@book{abramowitzHandbookMathematicalFunctions1965,
  title = {Handbook of {{Mathematical Functions}}: {{With Formulas}}, {{Graphs}}, and {{Mathematical Tables}}},
  shorttitle = {Handbook of {{Mathematical Functions}}},
  author = {Abramowitz, Milton and Stegun, Irene A.},
  year = {1965},
  month = jan,
  publisher = {{Courier Corporation}},
  abstract = {Vast compendium - 29 sets of tables, some to as high as 20 places.},
  googlebooks = {MtU8uP7XMvoC},
  isbn = {978-0-486-61272-0},
  langid = {english},
  keywords = {Mathematics / Functional Analysis,Mathematics / General},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Courier Corporation/1965/Abramowitz_Stegun_1965_Handbook of Mathematical Functions.pdf}
}

@article{anscombeGraphsStatisticalAnalysis1973,
  title = {Graphs in {{Statistical Analysis}}},
  author = {Anscombe, F. J.},
  year = {1973},
  month = feb,
  journal = {The American Statistician},
  volume = {27},
  number = {1},
  pages = {17--21},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.1973.10478966},
  urldate = {2023-09-13}
}

@article{basMathematicalModellingGranola2011,
  title = {Mathematical Modelling of Granola Breakage during Pipe Pneumatic Conveying},
  author = {Ba{\c s}, Nur{\c s}in and Pathare, Pankaj B. and Catak, Muammer and Fitzpatrick, John J. and Cronin, Kevin and Byrne, Edmond P.},
  year = {2011},
  month = jan,
  journal = {Powder Technology},
  series = {9th {{International Symposium}} on {{Agglomeration}} and 4th {{International Granulation Workshop}}, 2009},
  volume = {206},
  number = {1},
  pages = {170--176},
  issn = {0032-5910},
  doi = {10.1016/j.powtec.2010.06.015},
  urldate = {2023-07-07},
  abstract = {Granola is a baked aggregated food product which serves as a breakfast cereal or snack consisting of oats, cereals, nuts and honey. Particle breakage of aggregated granola can occur during conveying as product is transferred as part of the production process on its way to packaging. Such breakage occurs as a result of particle\textendash particle and particle\textendash wall collisions with the conveying equipment. In this work, a population balance model is developed to describe the breakage of granola as it is conveyed through a pneumatic conveying pipeline rig. The model incorporates the influence of conveying pressure, exposure time and pipeline geometry, and is also related to parameters associated with aggregate formation such as granulator mixing speed and time. The aggregates were formed in a high shear granulator subject to impeller agitation of 300rpm for 9min and were then propelled through a pipeline with a 90\textdegree{} bend at a number of different flow rates. Trials were carried out by applying compressed air at pressures of 200kPa, 300kPa and 400kPa while the aggregates were subjected to a number of recycles through the rig. Modelling of this breakage process was achieved by constructing the population balance equations (PBEs) in the form of a mass balance on the granola aggregates. The solutions to the PBEs were obtained by means of discretization through the application of the Markov chain method. When the size range of the system was divided into an appropriate number of states, the Markov chain method for the population balances exhibited a reasonable approximation for predicting the particle size distribution (PSD) over time particularly during the initial rig cycles.},
  langid = {english},
  keywords = {Breakage,Conveying,Markov chains,Population balance modelling},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Powder Technology/2011/Baş et al_2011_Mathematical modelling of granola breakage during pipe pneumatic conveying.pdf;/Users/steven/Zotero/storage/JZTXBPSM/S0032591010003141.html}
}

@article{benkoCommonFunctionalPrincipal2009,
  title = {Common Functional Principal Components},
  author = {Benko, Michal and H{\"a}rdle, Wolfgang and Kneip, Alois},
  year = {2009},
  month = feb,
  journal = {The Annals of Statistics},
  volume = {37},
  number = {1},
  pages = {1--34},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/07-AOS516},
  urldate = {2023-09-01},
  abstract = {Functional principal component analysis (FPCA) based on the Karhunen\textendash Lo\`eve decomposition has been successfully applied in many applications, mainly for one sample problems. In this paper we consider common functional principal components for two sample problems. Our research is motivated not only by the theoretical challenge of this data situation, but also by the actual question of dynamics of implied volatility (IV) functions. For different maturities the log-returns of IVs are samples of (smooth) random functions and the methods proposed here study the similarities of their stochastic behavior. First we present a new method for estimation of functional principal components from discrete noisy data. Next we present the two sample inference for FPCA and develop the two sample theory. We propose bootstrap tests for testing the equality of eigenvalues, eigenfunctions, and mean functions of two functional samples, illustrate the test-properties by simulation study and apply the method to the IV analysis.},
  keywords = {62G08,62H25,62P05,bootstrap,functional principal components,Nonparametric regression,two sample problem},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/The Annals of Statistics/2009/Benko et al_2009_Common functional principal components.pdf}
}

@article{berthiauxApplicationTheoryMarkov2005,
  title = {Application of the Theory of {{Markov}} Chains to Model Different Processes in Particle Technology},
  author = {Berthiaux, Henri and Mizonov, Vadim and Zhukov, Vladimir},
  year = {2005},
  month = sep,
  journal = {Powder Technology},
  series = {4th {{French Meeting}} on {{Powder Science}} and {{Technology}}},
  volume = {157},
  number = {1},
  pages = {128--137},
  issn = {0032-5910},
  doi = {10.1016/j.powtec.2005.05.019},
  urldate = {2023-07-08},
  abstract = {The essence of almost all processes with participation of particulate solids is similar: it is a transformation of a particle property, or properties. This suggests that a unified basis for examining the changes of this property with (for example) time, may be derived. In this paper, the general strategy of building the Markov chain models and computational analysis of characteristics of a process is described, and some examples of application of the approach to model grinding, classification, grinding with internal classification, mixing, agglomeration, etc, are shown. The use of multidimensional models to consider simultaneously different properties is emphasised. The approach also allows taking into account non-linear phenomena, which are very typical of particulate processes but are very seldom considered in usual models.},
  langid = {english},
  keywords = {Markov chains,Particle technology,Transition matrix},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Powder Technology/2005/Berthiaux et al. - 2005 - Application of the theory of Markov chains to mode.pdf;/Users/steven/Zotero/storage/2MFSKMNF/S0032591005002354.html}
}

@article{bessePrincipalComponentsAnalysis1986,
  title = {Principal Components Analysis of Sampled Functions},
  author = {Besse, Philippe and Ramsay, J. O.},
  year = {1986},
  month = jun,
  journal = {Psychometrika},
  volume = {51},
  number = {2},
  pages = {285--311},
  issn = {1860-0980},
  doi = {10.1007/BF02293986},
  urldate = {2023-07-08},
  abstract = {This paper describes a technique for principal components analysis of data consisting ofn functions each observed atp argument values. This problem arises particularly in the analysis of longitudinal data in which some behavior of a number of subjects is measured at a number of points in time. In such cases information about the behavior of one or more derivatives of the function being sampled can often be very useful, as for example in the analysis of growth or learning curves. It is shown that the use of derivative information is equivalent to a change of metric for the row space in classical principal components analysis. The reproducing kernel for the Hilbert space of functions plays a central role, and defines the best interpolating functions, which are generalized spline functions. An example is offered of how sensitivity to derivative information can reveal interesting aspects of the data.},
  langid = {english},
  keywords = {Green's functions,Hilbert space of functions,interpolation,reproducing kernel,smoothing,spline functions},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Psychometrika/1986/Besse and Ramsay - 1986 - Principal components analysis of sampled functions.pdf}
}

@article{caiOptimalEstimationMean2011a,
  title = {Optimal Estimation of the Mean Function Based on Discretely Sampled Functional Data: {{Phase}} Transition},
  shorttitle = {Optimal Estimation of the Mean Function Based on Discretely Sampled Functional Data},
  author = {Cai, T. Tony and Yuan, Ming},
  year = {2011},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {39},
  number = {5},
  pages = {2330--2355},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/11-AOS898},
  urldate = {2023-08-24},
  abstract = {The problem of estimating the mean of random functions based on discretely sampled data arises naturally in functional data analysis. In this paper, we study optimal estimation of the mean function under both common and independent designs. Minimax rates of convergence are established and easily implementable rate-optimal estimators are introduced. The analysis reveals interesting and different phase transition phenomena in the two cases. Under the common design, the sampling frequency solely determines the optimal rate of convergence when it is relatively small and the sampling frequency has no effect on the optimal rate when it is large. On the other hand, under the independent design, the optimal rate of convergence is determined jointly by the sampling frequency and the number of curves when the sampling frequency is relatively small. When it is large, the sampling frequency has no effect on the optimal rate. Another interesting contrast between the two settings is that smoothing is necessary under the independent design, while, somewhat surprisingly, it is not essential under the common design.},
  keywords = {functional data,mean function,minimax,phase transition,rate of convergence,‎reproducing kernel Hilbert ‎space,smoothing splines,Sobolev space},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/The Annals of Statistics/2011/Cai_Yuan_2011_Optimal estimation of the mean function based on discretely sampled functional2.pdf}
}

@article{catakDiscreteSolutionBreakage2010,
  title = {Discrete {{Solution}} of the {{Breakage Equation Using Markov Chains}}},
  author = {Catak, Muammer and Bas, Nursin and Cronin, Kevin and Fitzpatrick, John J. and Byrne, Edmond P.},
  year = {2010},
  month = sep,
  journal = {Industrial \& Engineering Chemistry Research},
  volume = {49},
  number = {17},
  pages = {8248--8257},
  publisher = {{American Chemical Society}},
  issn = {0888-5885},
  doi = {10.1021/ie100216g},
  urldate = {2023-07-08},
  abstract = {Analytical solution of population balance equations (PBEs) may be impossible except for some simple cases. In the literature there are a number of methods to solve PBEs including discrete methods, Monte Carlo simulation, and method of moments. In this paper, the Markov chain is presented as a discrete solution for a population balance equation of a breakage process for determining the particle size distribution (PSD) over time. The transition matrix P, which is the key operator of a Markov chain, is built using breakage equations. Thereafter, from calculating transition matrix, P, the particle size distribution of the system is easily evaluated using the Markov chain. According to simulation results, if the size range of the system is divided into a sufficient number of states and an appropriate transition time step was chosen, then results from the Markov chain are in agreement with the analytical solution of PBEs governed by the same breakage functions. In addition to theoretical illustration, the Markov theory was employed to model the breakage process of aggregated food products passing through a pneumatic conveying pipeline rig.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Industrial & Engineering Chemistry Research/2010/Catak et al. - 2010 - Discrete Solution of the Breakage Equation Using M.pdf}
}

@book{chenHandbookDataVisualization2008,
  title = {Handbook of {{Data Visualization}}},
  author = {Chen, Chun-houh and H{\"a}rdle, Wolfgang and Unwin, Antony},
  year = {2008},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-33037-0},
  urldate = {2023-09-13},
  isbn = {978-3-540-33036-3 978-3-540-33037-0},
  langid = {english},
  keywords = {Analysis,best fit,Cluster analysis,computer,data analysis,Fitting,Java,multidimensional scaling,Projection pursuit,statistics,visualization,XML},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2008/Chen et al_2008_Handbook of Data Visualization.pdf}
}

@article{chiouMultivariateFunctionalPrincipal2014,
  title = {Multivariate {{Functional Principal Component Analysis}}: {{A Normalization Approach}}},
  shorttitle = {Multivariate {{Functional Principal Component Analysis}}},
  author = {Chiou, Jeng-Min and Chen, Yu-Ting and Yang, Ya-Fang},
  year = {2014},
  journal = {Statistica Sinica},
  volume = {24},
  number = {4},
  eprint = {24310959},
  eprinttype = {jstor},
  pages = {1571--1596},
  publisher = {{Institute of Statistical Science, Academia Sinica}},
  issn = {1017-0405},
  urldate = {2023-07-08},
  abstract = {We propose an extended version of the classical Karhunen-Lo\`eve expansion of a multivariate random process, termed a normalized multivariate functional principal component (mFPCn) representation. This takes variations between the components of the process into account and takes advantage of component dependencies through the pairwise cross-covariance functions. This approach leads to a single set of multivariate functional principal component scores, which serve well as a proxy for multivariate functional data. We derive the consistency properties for the estimates of the mFPCn, and the asymptotic distributions for statistical inferences. We illustrate the finite sample performance of this approach through the analysis of a traffic flow data set, including an application to clustering and a simulation study. The mFPCn approach serves as a basic and useful statistical tool for multivariate functional data analysis.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Statistica Sinica/2014/Chiou et al_2014_Multivariate Functional Principal Component Analysis.pdf}
}

@article{clevelandRobustLocallyWeighted1979,
  title = {Robust {{Locally Weighted Regression}} and {{Smoothing Scatterplots}}},
  author = {Cleveland, William S.},
  year = {1979},
  journal = {Journal of the American Statistical Association},
  volume = {74},
  number = {368},
  eprint = {2286407},
  eprinttype = {jstor},
  pages = {829--836},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0162-1459},
  doi = {10.2307/2286407},
  urldate = {2023-07-08},
  abstract = {The visual information on a scatterplot can be greatly enhanced, with little additional cost, by computing and plotting smoothed points. Robust locally weighted regression is a method for smoothing a scatterplot, (x\textsubscript{i}, y\textsubscript{i}), i = 1, {$\cdots$}, n, in which the fitted value at x\textsubscript{k} is the value of a polynomial fit to the data using weighted least squares, where the weight for (x\textsubscript{i}, y\textsubscript{i}) is large if x\textsubscript{i} is close to x\textsubscript{k} and small if it is not. A robust fitting procedure is used that guards against deviant points distorting the smoothed points. Visual, computational, and statistical issues of robust locally weighted regression are discussed. Several examples, including data on lead intoxication, are used to illustrate the methodology.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the American Statistical Association/1979/Cleveland_1979_Robust Locally Weighted Regression and Smoothing Scatterplots.pdf}
}

@misc{golovkineAdaptiveEstimationIrregular2023,
  title = {Adaptive Estimation of Irregular Mean and Covariance Functions},
  author = {Golovkine, Steven and Klutchnikoff, Nicolas and Patilea, Valentin},
  year = {2023},
  month = jul,
  number = {arXiv:2108.06507},
  eprint = {2108.06507},
  primaryclass = {math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2108.06507},
  urldate = {2023-09-09},
  abstract = {Nonparametric estimators for the mean and the covariance functions of functional data are proposed. The setup covers a wide range of practical situations. The random trajectories are, not necessarily differentiable, have unknown regularity, and are measured with error at discrete design points. The measurement error could be heteroscedastic. The design points could be either randomly drawn or common for all curves. The estimators depend on the local regularity of the stochastic process generating the functional data. We consider a simple estimator of this local regularity which exploits the replication and regularization features of functional data. Next, we use the ``smoothing first, then estimate'' approach for the mean and the covariance functions. They can be applied with both sparsely or densely sampled curves, are easy to calculate and to update, and perform well in simulations. Simulations built upon an example of real data set, illustrate the effectiveness of the new approach.},
  archiveprefix = {arxiv},
  keywords = {{62R10, 62G05, 62M09},Mathematics - Statistics Theory},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/arXiv/2023/Golovkine et al_2023_Adaptive estimation of irregular mean and covariance functions.pdf;/Users/steven/Zotero/storage/M8RCD7IV/2108.html}
}

@article{golovkineClusteringMultivariateFunctional2022,
  title = {Clustering Multivariate Functional Data Using Unsupervised Binary Trees},
  author = {Golovkine, Steven and Klutchnikoff, Nicolas and Patilea, Valentin},
  year = {2022},
  month = apr,
  journal = {Computational Statistics \& Data Analysis},
  volume = {168},
  pages = {107376},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2021.107376},
  urldate = {2023-09-01},
  abstract = {A model-based clustering algorithm is proposed for a general class of functional data for which the components could be curves or images. The random functional data realizations could be measured with errors at discrete, and possibly random, points in the definition domain. The idea is to build a set of binary trees by recursive splitting of the observations. The number of groups are determined in a data-driven way. The new algorithm provides easily interpretable results and fast predictions for online data sets. Results on simulated datasets reveal good performance in various complex settings. The methodology is applied to the analysis of vehicle trajectories on a German roundabout.},
  keywords = {Gaussian mixtures,Model-based clustering,Multivariate functional principal components},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Computational Statistics & Data Analysis/2022/Golovkine et al_2022_Clustering multivariate functional data using unsupervised binary trees.pdf;/Users/steven/Zotero/storage/RFZMW5EA/S0167947321002103.html}
}

@misc{golovkineFDApyPythonPackage2021,
  title = {{{FDApy}}: A {{Python}} Package for Functional Data},
  shorttitle = {{{FDApy}}},
  author = {Golovkine, Steven},
  year = {2021},
  month = jan,
  number = {arXiv:2101.11003},
  eprint = {2101.11003},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2101.11003},
  urldate = {2023-09-09},
  abstract = {We introduce the Python package, FDApy, as an implementation of functional data. This package provide modules for the analysis of such data. It includes classes for different dimensional data as well as irregularly sampled functional data. A simulation toolbox is also provided. It might be used to simulate different clusters of functional data. Some methodologies to handle these data are implemented, such as dimension reduction and clustering. New methods can be easily added. The package is publicly available on the Python Package Index and Github.},
  archiveprefix = {arxiv},
  keywords = {62R10 (Primary),Computer Science - Machine Learning,Computer Science - Mathematical Software,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/arXiv/2021/Golovkine_2021_FDApy.pdf;/Users/steven/Zotero/storage/MXCQQVFS/2101.html}
}

@article{golovkineLearningSmoothnessNoisy2022,
  title = {Learning the Smoothness of Noisy Curves with Application to Online Curve Estimation},
  author = {Golovkine, Steven and Klutchnikoff, Nicolas and Patilea, Valentin},
  year = {2022},
  month = jan,
  journal = {Electronic Journal of Statistics},
  volume = {16},
  number = {1},
  pages = {1485--1560},
  publisher = {{Institute of Mathematical Statistics and Bernoulli Society}},
  issn = {1935-7524, 1935-7524},
  doi = {10.1214/22-EJS1997},
  urldate = {2023-09-01},
  abstract = {Combining information both within and across trajectories, we propose a simple estimator for the local regularity of the trajectories of a stochastic process. Independent trajectories are measured with errors at randomly sampled time points. The proposed approach is model-free and applies to a large class of stochastic processes. Non-asymptotic bounds for the concentration of the estimator are derived. Given the estimate of the local regularity, we build a nearly optimal local polynomial smoother from the curves from a new, possibly very large sample of noisy trajectories. We derive non-asymptotic pointwise risk bounds uniformly over the new set of curves. Our estimates perform well in simulations, in both cases of differentiable or non-differentiable trajectories. Real data sets illustrate the effectiveness of the new approaches.},
  keywords = {62G05,62M09,62R10,adaptive optimal smoothing,Functional data analysis,H\"older exponent,traffic flow},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Electronic Journal of Statistics/2022/Golovkine et al_2022_Learning the smoothness of noisy curves with application to online curve.pdf}
}

@misc{golovkineUseGramMatrix2023,
  title = {On the Use of the {{Gram}} Matrix for Multivariate Functional Principal Components Analysis},
  author = {Golovkine, Steven and Gunning, Edward and Simpkin, Andrew J. and Bargary, Norma},
  year = {2023},
  month = jun,
  number = {arXiv:2306.12949},
  eprint = {2306.12949},
  primaryclass = {stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2306.12949},
  urldate = {2023-09-09},
  abstract = {Dimension reduction is crucial in functional data analysis (FDA). The key tool to reduce the dimension of the data is functional principal component analysis. Existing approaches for functional principal component analysis usually involve the diagonalization of the covariance operator. With the increasing size and complexity of functional datasets, estimating the covariance operator has become more challenging. Therefore, there is a growing need for efficient methodologies to estimate the eigencomponents. Using the duality of the space of observations and the space of functional features, we propose to use the inner-product between the curves to estimate the eigenelements of multivariate and multidimensional functional datasets. The relationship between the eigenelements of the covariance operator and those of the inner-product matrix is established. We explore the application of these methodologies in several FDA settings and provide general guidance on their usability.},
  archiveprefix = {arxiv},
  keywords = {62R10,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/arXiv/2023/Golovkine et al_2023_On the use of the Gram matrix for multivariate functional principal components.pdf;/Users/steven/Zotero/storage/ENF6DK3X/2306.html}
}

@article{gonzalezRepresentingFunctionalData2010,
  title = {Representing Functional Data in Reproducing {{Kernel Hilbert Spaces}} with Applications to Clustering and Classification},
  author = {Gonz{\'a}lez, Javier and Mu{\~n}oz, Alberto},
  year = {2010},
  month = may,
  journal = {DES - Working Papers. Statistics and Econometrics. WS},
  number = {ws102713},
  publisher = {{Universidad Carlos III de Madrid. Departamento de Estad\'istica}},
  urldate = {2023-07-08},
  abstract = {Functional data are difficult to manage for many traditional statistical techniques given their very high (or intrinsically infinite) dimensionality. The reason is that functional data are essentially functions and most algorithms are designed to work with (low) finite-dimensional vectors. Within this context we propose techniques to obtain finitedimensional representations of functional data. The key idea is to consider each functional curve as a point in a general function space and then project these points onto a Reproducing Kernel Hilbert Space with the aid of Regularization theory. In this work we describe the projection method, analyze its theoretical properties and propose a model selection procedure to select appropriate Reproducing Kernel Hilbert spaces to project the functional data.},
  langid = {english},
  keywords = {Functional data},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/DES - Working Papers. Statistics and Econometrics. WS/2010/González_Muñoz_2010_Representing functional data in reproducing Kernel Hilbert Spaces with.pdf;/Users/steven/Zotero/storage/U9SIH6GN/ws102713.html}
}

@article{happ-kurzObjectOrientedSoftwareFunctional2020,
  title = {Object-{{Oriented Software}} for {{Functional Data}}},
  author = {{Happ-Kurz}, Clara},
  year = {2020},
  month = apr,
  journal = {Journal of Statistical Software},
  volume = {93},
  pages = {1--38},
  issn = {1548-7660},
  doi = {10.18637/jss.v093.i05},
  urldate = {2023-07-31},
  abstract = {This paper introduces the funData R package as an object-oriented implementation of functional data. It implements a unified framework for dense univariate and multivariate functional data on one- and higher dimensional domains as well as for irregular functional data. The aim of this package is to provide a user-friendly, self-contained core toolbox for functional data, including important functionalities for creating, accessing and modifying functional data objects, that can serve as a basis for other packages. The package further contains a full simulation toolbox, which is a useful feature when implementing and testing new methodological developments. Based on the theory of object-oriented data analysis, it is shown why it is natural to implement functional data in an object-oriented manner. The classes and methods provided by funData are illustrated in many examples using two freely available datasets. The MFPCA package, which implements multivariate functional principal component analysis, is presented as an example for an advanced methodological package that uses the funData package as a basis, including a case study with real data. Both packages are publicly available on GitHub and the Comprehensive R Archive Network.},
  copyright = {Copyright (c) 2020 Clara Happ-Kurz},
  langid = {english},
  keywords = {functional data analysis,functional principal component analysis,multivariate functional data,object orientation,simulation},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Statistical Software/2020/Happ-Kurz_2020_Object-Oriented Software for Functional Data.pdf}
}

@article{happMultivariateFunctionalPrincipal2018,
  title = {Multivariate {{Functional Principal Component Analysis}} for {{Data Observed}} on {{Different}} ({{Dimensional}}) {{Domains}}},
  author = {Happ, Clara and Greven, Sonja},
  year = {2018},
  month = apr,
  journal = {Journal of the American Statistical Association},
  volume = {113},
  number = {522},
  pages = {649--659},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2016.1273115},
  urldate = {2023-07-08},
  abstract = {Existing approaches for multivariate functional principal component analysis are restricted to data on the same one-dimensional interval. The presented approach focuses on multivariate functional data on different domains that may differ in dimension, such as functions and images. The theoretical basis for multivariate functional principal component analysis is given in terms of a Karhunen\textendash Lo\`eve Theorem. For the practically relevant case of a finite Karhunen\textendash Lo\`eve representation, a relationship between univariate and multivariate functional principal component analysis is established. This offers an estimation strategy to calculate multivariate functional principal components and scores based on their univariate counterparts. For the resulting estimators, asymptotic results are derived. The approach can be extended to finite univariate expansions in general, not necessarily orthonormal bases. It is also applicable for sparse functional data or data with measurement error. A flexible R implementation is available on CRAN. The new method is shown to be competitive to existing approaches for data observed on a common one-dimensional domain. The motivating application is a neuroimaging study, where the goal is to explore how longitudinal trajectories of a neuropsychological test score covary with FDG-PET brain scans at baseline. Supplementary material, including detailed proofs, additional simulation results, and software is available online.},
  keywords = {Dimension reduction,Functional data analysis,Image analysis,Multivariate functional data},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the American Statistical Association/2018/Happ and Greven - 2018 - Multivariate Functional Principal Component Analys_supp.pdf;/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the American Statistical Association/2018/Happ and Greven - 2018 - Multivariate Functional Principal Component Analys.pdf}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-84858-7},
  urldate = {2023-07-07},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2009/Hastie et al_2009_The Elements of Statistical Learning_outline.pdf;/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2009/Hastie et al. - 2009 - The Elements of Statistical Learning.pdf}
}

@article{hillStatisticsMultipleParticle1996,
  title = {Statistics of Multiple Particle Breakage},
  author = {Hill, Priscilla J. and Ng, Ka M.},
  year = {1996},
  journal = {AIChE Journal},
  volume = {42},
  number = {6},
  pages = {1600--1611},
  issn = {1547-5905},
  doi = {10.1002/aic.690420611},
  urldate = {2023-07-08},
  abstract = {A method for generating theoretical breakage distribution functions for multiple particle breakage is presented. It starts with the joint probability function that accounts for all the child particles; it is then reduced to the marginal probability function commonly used in the breakage equation. This method is flexible enough to allow the user to choose the number of child particles and the functional form to be used. The method is demonstrated with both product and summation functions with a power-law form. To facilitate the use of these theoretical functions for statistical analyses, a companion discretized breakage equation is developed. The new equation guarantees the conservation of mass and correct prediction of the total number of particles despite discretization. It is easy to use because it is a set of ordinary differential equations and applicable to both equal-size and geometric-size intervals. Simulation results show that different breakage distribution functions coupled with different breakage rates can produce almost indistinguishable particle-size distributions, signifying the need for further work in this area.},
  copyright = {Copyright \textcopyright{} 1996 American Institute of Chemical Engineers},
  langid = {english},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/AIChE Journal/1996/Hill and Ng - 1996 - Statistics of multiple particle breakage.pdf;/Users/steven/Zotero/storage/6H7B9A22/aic.html}
}

@article{jacquesModelbasedClusteringMultivariate2014,
  title = {Model-Based Clustering for Multivariate Functional Data},
  author = {Jacques, Julien and Preda, Cristian},
  year = {2014},
  month = mar,
  journal = {Computational Statistics \& Data Analysis},
  volume = {71},
  pages = {92--106},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2012.12.004},
  urldate = {2023-07-08},
  abstract = {The first model-based clustering algorithm for multivariate functional data is proposed. After introducing multivariate functional principal components analysis (MFPCA), a parametric mixture model, based on the assumption of normality of the principal component scores, is defined and estimated by an EM-like algorithm. The main advantage of the proposed model is its ability to take into account the dependence among curves. Results on simulated and real datasets show the efficiency of the proposed method.},
  langid = {english},
  keywords = {Density approximation,EM-algorithm,Model-based clustering,Multivariate functional data,Multivariate functional principal component analysis},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Computational Statistics & Data Analysis/2014/Jacques_Preda_2014_Model-based clustering for multivariate functional data.pdf;/Users/steven/Zotero/storage/8GDK5ZI4/S0167947312004380.html}
}

@book{karhunenUeberLineareMethoden1947,
  title = {{\"Uber lineare Methoden in der Wahrscheinlichkeitsrechnung}},
  author = {Karhunen, Kari},
  year = {1947},
  series = {{Suomalaisen Tiedeakatemian toimituksia}},
  number = {ARRAY(0x55c9032fd4e0)},
  publisher = {{Zugl.: Helsinki, Univ., Diss., 1947}},
  address = {{Helsinki}},
  langid = {german}
}

@article{kastnerBayesianParameterEstimation2013,
  title = {Bayesian Parameter Estimation for a Jet-Milling Model Using {{Metropolis}}\textendash{{Hastings}} and {{Wang}}\textendash{{Landau}} Sampling},
  author = {Kastner, Catharine A. and Braumann, Andreas and Man, Peter L. W. and Mosbach, Sebastian and Brownbridge, George P. E. and Akroyd, Jethro and Kraft, Markus and Himawan, Chrismono},
  year = {2013},
  month = feb,
  journal = {Chemical Engineering Science},
  volume = {89},
  pages = {244--257},
  issn = {0009-2509},
  doi = {10.1016/j.ces.2012.11.027},
  urldate = {2023-07-08},
  abstract = {Bayesian parameter estimates for a computationally expensive multi-response jet-milling model are computed using the Metropolis\textendash Hastings and Wang\textendash Landau Markov Chain Monte Carlo sampling algorithms. The model is accompanied by data obtained from 74 experiments at different process settings which is used to estimate the model parameters. The experimentally measured quantities are the 10th, 50th and 90th quantiles of the resulting particle size distributions. Parameter estimation is performed on a population balance jet-milling model composed of three subprocesses: jet expansion, milling and classification. The model contains eight parameters requiring estimation and can compute the same quantities that are determined in the experiments. As the model is computationally expensive to solve, the sampling algorithms are applied to a surrogate model to establish algorithm specific parameters and to obtain model parameter estimates. The resulting parameter estimates are given with a discussion of their reliability and the observed behaviour of the two sampling algorithms. Comparison of the autocorrelation function between samples generated by the two algorithms shows that the Wang\textendash Landau algorithm exhibits more rapid decay. Trace plots of the parameter samples from the two algorithms appear to be analogous and encourage the supposition that the Markov Chains have converged to the distribution of interest. One- and two-dimensional density plots indicate a unimodal distribution for all parameters, which suggests that the obtained estimates are unique. The two-dimensional density plots also suggest correlation between at least two of the model parameters. The realised distribution generated by both algorithms produced consistent results and demonstrated similar behaviour. For the application considered in this work, the Wang\textendash Landau algorithm is found to exhibit superior performance with respect to the correlation and equivalent performance in all other respects.},
  langid = {english},
  keywords = {Markov chain Monte Carlo,Mathematical modelling,Parameter identification,Particulate processing,Population balance,Wang\textendash Landau},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Chemical Engineering Science/2013/Kastner et al. - 2013 - Bayesian parameter estimation for a jet-milling mo.pdf;/Users/steven/Zotero/storage/HHMPLUFA/S000925091200677X.html}
}

@book{loeveFonctionsAleatoiresSecond1965,
  title = {{Fonctions al\'eatoires du second ordre...}},
  author = {Lo{\`e}ve, Michel},
  year = {1965},
  googlebooks = {Was5XwAACAAJ},
  langid = {french}
}

@article{longEstimatingReactionParameters2022,
  title = {Estimating Reaction Parameters in Mechanism-Enabled Population Balance Models of Nanoparticle Size Distributions: {{A Bayesian}} Inverse Problem Approach},
  shorttitle = {Estimating Reaction Parameters in Mechanism-Enabled Population Balance Models of Nanoparticle Size Distributions},
  author = {Long, Danny K. and Bangerth, Wolfgang and Handwerk, Derek R. and Whitehead, Christopher B. and Shipman, Patrick D. and Finke, Richard G.},
  year = {2022},
  journal = {Journal of Computational Chemistry},
  volume = {43},
  number = {1},
  pages = {43--56},
  issn = {1096-987X},
  doi = {10.1002/jcc.26770},
  urldate = {2023-07-08},
  abstract = {In order to quantitatively predict nano- as well as other particle-size distributions, one needs to have both a mathematical model and estimates of the parameters that appear in these models. Here, we show how one can use Bayesian inversion to obtain statistical estimates for the parameters that appear in recently derived mechanism-enabled population balance models (ME-PBM) of nanoparticle growth. The Bayesian approach addresses the question of ``how well do we know our parameters, along with their uncertainties?.'' The results reveal that Bayesian inversion statistical analysis on an example, prototype nanoparticle formation system allows one to estimate not just the most likely rate constants and other parameter values, but also their SDs, confidence intervals, and other statistical information. Moreover, knowing the reliability of the mechanistic model's parameters in turn helps inform one about the reliability of the proposed mechanism, as well as the reliability of its predictions. The paper can also be seen as a tutorial with the additional goal of achieving a ``Gold Standard'' Bayesian inversion ME-PBM benchmark that others can use as a control to check their own use of this methodology for other systems of interest throughout nature. Overall, the results provide strong support for the hypothesis that there is substantial value in using a Bayesian inversion methodology for parameter estimation in particle formation systems.},
  copyright = {\textcopyright{} 2021 Wiley Periodicals LLC.},
  langid = {english},
  keywords = {Bayesian inversion,kinetics and mechanism,nanoparticles,nucleation and growth,particle size distribution,population balance modeling},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Computational Chemistry/2022/Long et al. - 2022 - Estimating reaction parameters in mechanism-enable.pdf}
}

@article{martinezrodriguezParticleAgglomerationFlows2022,
  title = {Particle Agglomeration in Flows: {{Fast}} Data-Driven Spatial Decomposition Algorithm for {{CFD}} Simulations},
  shorttitle = {Particle Agglomeration in Flows},
  author = {Mart{\'i}nez Rodr{\'i}guez, Kerlyns and Bossy, Mireille and Henry, Christophe},
  year = {2022},
  month = apr,
  journal = {International Journal of Multiphase Flow},
  volume = {149},
  pages = {103962},
  issn = {0301-9322},
  doi = {10.1016/j.ijmultiphaseflow.2021.103962},
  urldate = {2023-07-08},
  abstract = {Computational fluid dynamics simulations in practical industrial/environmental cases often involve non-homogeneous concentrations of particles. In Euler\textendash Lagrange simulations, this can induce the propagation of numerical error when the number of collision/agglomeration events is computed using mean-field approaches. In fact, mean-field statistical collision models allow to sample the number of collision events using a priori information on the frequency of collisions (the collision kernel). Yet, since such methods often rely on the mesh used for the Eulerian simulation of the fluid phase, the particle number concentration within a given cell might not be homogeneous, leading to numerical errors. In this article, we apply the data-driven spatial decomposition (D2SD) algorithm to control such error in simulations of particle agglomeration. Significant improvements are made to design a fast D2SD version, minimising the additional computational cost by developing re-meshing criteria. Through the application to some practical simulation cases, we show the importance of splitting the domain when computing agglomeration events in Euler/Lagrange simulations, so that within each elementary cell there is a spatially uniform distribution of particles.},
  langid = {english},
  keywords = {Agglomeration,Computational Fluid Dynamics (CFD),Mesh-independence,Particle-based mesh,Particle-laden flows,Population Balance Equation (PBE)},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/International Journal of Multiphase Flow/2022/Martínez Rodríguez et al_2022_Particle agglomeration in flows.pdf;/Users/steven/Zotero/storage/LTFAYIT3/S0301932221003578.html}
}

@techreport{mohajerComparisonGapStatistic2010,
  type = {{{workingPaper}}},
  title = {A Comparison of {{Gap}} Statistic Definitions with and without Logarithm Function},
  author = {Mohajer, Mojgan and Englmeier, Karl-Hans and Schmid, Volker J.},
  year = {2010},
  month = dec,
  volume = {96},
  doi = {10.5282/ubm/epub.11920},
  urldate = {2023-07-08},
  abstract = {The Gap statistic is a standard method for determining the number of clusters in a set of data. The Gap statistic standardizes the graph of \$\textbackslash log(W\_\{k\})\$, where \$W\_\{k\}\$ is the within-cluster dispersion, by comparing it to its expectation under an appropriate null reference distribution of the data. We suggest to use \$W\_\{k\}\$ instead of \$\textbackslash log(W\_\{k\})\$, and to compare it to the expectation of \$W\_\{k\}\$ under a null reference distribution. In fact, whenever a number fulfills the original Gap statistic inequality, this number also fulfills the inequality of a Gap statistic using \$W\_\{k\}\$, but not \textbackslash textit\{vice versa\}. The two definitions of the Gap function are evaluated on several simulated data set and on a real data of DCE-MR images.},
  langid = {english},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/undefined/2010/Mohajer et al_2010_A comparison of Gap statistic definitions with and without logarithm function.pdf;/Users/steven/Zotero/storage/Y3IPPS59/11920.html}
}

@article{mouraEstimationParametersSelection2022,
  title = {Estimation {{Of Parameters And Selection Of Models Applied To Population Balance Dynamics Via Approximate Bayesian Computational}}},
  author = {Moura, Carlos Henrique and Viegas, Bruno Marques and Tavares, Maria and Macedo, Emanuel and Estumano, Diego Cardoso},
  year = {2022},
  month = may,
  journal = {Journal of Heat and Mass Transfer Research},
  volume = {9},
  number = {1},
  pages = {53--64},
  publisher = {{Semnan University}},
  issn = {2345-508X},
  doi = {10.22075/jhmtr.2022.25186.1361},
  urldate = {2023-07-08},
  abstract = {Population balance models mathematically describe the particle size distribution based on modeling physical phenomena that influence the distribution, such as aggregation, growth, and breakage. Due to the wide range of mechanisms present, several models are presented in the literature since several hypotheses are considered. In the current work, the Approximate Bayesian Computational statistical technique was used to select four different models of population balance and estimate their parameters. Three strategies were applied to the drawing of parameters, evaluating the correlation between the parameters of the models. An adaptive tolerance in each population and a stopping criterion, based on Morozov's uncertainty principle, were used for the algorithm. The technique obtained reasonable estimates for the phenomenological rates of the models. The algorithm correctly selected the model used for generating measurements, and the three draw strategies demonstrated good applicability. The results obtained showed that the algorithm presented accuracy and precision in estimating the parameters and properly selected the models analyzed.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Heat and Mass Transfer Research/2022/Moura et al_2022_Estimation Of Parameters And Selection Of Models Applied To Population Balance.pdf}
}

@article{mouraParameterEstimationPopulation2021,
  title = {Parameter {{Estimation}} in {{Population Balance}} through {{Bayesian}} ‎{{Technique Markov Chain Monte Carlo}}},
  author = {Moura, Carlos H. R. and Viegas, Bruno M. and Tavares, Maria R. M. and Mac{\^e}do, Emanuel N. and Estumano, Diego C. and Quaresma, Jo{\~a}o N. N.},
  year = {2021},
  month = apr,
  journal = {Journal of Applied and Computational Mechanics},
  volume = {7},
  number = {2},
  pages = {890--901},
  publisher = {{Shahid Chamran University of Ahvaz}},
  issn = {2383-4536},
  doi = {10.22055/jacm.2021.35741.2725},
  urldate = {2023-07-08},
  abstract = {In this work, the Markov Chain Monte Carlo is applied to estimate parameters that represent mechanisms that describe particles' dynamics in particulate systems from the literature's proposed models. Initially, the reduced sensitivity coefficient is evaluated to verify which parameters could be estimated simultaneously. The technique is then applied to estimate the models' parameters in different numerical scenarios to determine the rates that influence population dynamics. After the analyzes are performed, the estimates show good precision, accuracy, and a good fit between the measured and estimated state variables. The results show that the Markov chain Monte Carlo can determine the rates of population balance phenomenon.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Applied and Computational Mechanics/2021/Moura et al_2021_Parameter Estimation in Population Balance through Bayesian Technique Markov.pdf}
}

@article{pattersonStochasticWeightedParticle2011,
  title = {Stochastic Weighted Particle Methods for Population Balance Equations},
  author = {Patterson, Robert I. A. and Wagner, Wolfgang and Kraft, Markus},
  year = {2011},
  month = aug,
  journal = {Journal of Computational Physics},
  volume = {230},
  number = {19},
  pages = {7456--7472},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2011.06.011},
  urldate = {2023-07-08},
  abstract = {A class of coagulation weight transfer functions is constructed, each member of which leads to a stochastic particle algorithm for the numerical treatment of population balance equations. These algorithms are based on systems of weighted computational particles and the weight transfer functions are constructed such that the number of computational particles does not change during coagulation events. The algorithms also facilitate the simulation of physical processes that change single particles, such as growth, or other surface reactions. Four members of the algorithm family have been numerically validated by comparison to analytic solutions to simple problems. Numerical experiments have been performed for complex laminar premixed flame systems in which members of the class of stochastic weighted particle methods were compared to each other and to a direct simulation algorithm. Two of the weighted algorithms have been shown to offer performance advantages over the direct simulation algorithm in situations where interest is focused on the larger particles in a system. The extent of this advantage depends on the particular system and on the quantities of interest.},
  langid = {english},
  keywords = {Coagulation,Markov chain,Monte Carlo,Population balance,Soot,Weighted particle},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Computational Physics/2011/Patterson et al. - 2011 - Stochastic weighted particle methods for populatio.pdf;/Users/steven/Zotero/storage/FCX6W3CG/S0021999111003603.html}
}

@article{ramkrishnaPopulationBalanceModeling2014,
  title = {Population Balance Modeling: Current Status and Future Prospects},
  shorttitle = {Population Balance Modeling},
  author = {Ramkrishna, Doraiswami and Singh, Meenesh R.},
  year = {2014},
  journal = {Annual Review of Chemical and Biomolecular Engineering},
  volume = {5},
  pages = {123--146},
  issn = {1947-5438},
  doi = {10.1146/annurev-chembioeng-060713-040241},
  abstract = {Population balance modeling is undergoing phenomenal growth in its applications, and this growth is accompanied by multifarious reviews. This review aims to fortify the model's fundamental base, as well as point to a variety of new applications, including modeling of crystal morphology, cell growth and differentiation, gene regulatory processes, and transfer of drug resistance. This is accomplished by presenting the many faces of population balance equations that arise in the foregoing applications.},
  langid = {english},
  pmid = {24606333},
  keywords = {Algorithms,biofilm growth,Cell Physiological Phenomena,crystal morphology,Crystallization,Gene Expression Regulation,gene regulatory processes,{Models, Theoretical},personalized medicine,Precision Medicine,stem cell differentiation,stochastic internal coordinates,Stochastic Processes,Tissue Engineering},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Annual Review of Chemical and Biomolecular Engineering/2014/Ramkrishna and Singh - 2014 - Population balance modeling current status and fu.pdf}
}

@book{ramsayFunctionalDataAnalysis2005,
  title = {Functional {{Data Analysis}}},
  author = {Ramsay, J. O. and Silverman, B. W.},
  year = {2005},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/b98888},
  urldate = {2023-07-07},
  isbn = {978-0-387-40080-8 978-0-387-22751-1},
  langid = {english},
  keywords = {correlation,data analysis,Fitting,Generalized linear model,linear regression},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2005/Ramsay and Silverman - 2005 - Functional Data Analysis.pdf;/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2005/Ramsay_Silverman_2005_Functional Data Analysis_outline.pdf}
}

@book{reedFunctionalAnalysis1980,
  title = {Functional {{Analysis}}},
  author = {Reed, Michael and Simon, Barry},
  year = {1980},
  month = jan,
  publisher = {{Academic Press}},
  address = {{New York}},
  abstract = {This book is the first of a multivolume series devoted to an exposition of functional analysis methods in modern mathematical physics. It describes the fundamental principles of functional analysis and is essentially self-contained, although there are occasional references to later volumes. We have included a few applications when we thought that they would provide motivation for the reader. Later volumes describe various advanced topics in functional analysis and give numerous applications in classical physics, modern physics, and partial differential equations.},
  isbn = {978-0-12-585050-6},
  langid = {english},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Academic Press/1980/Reed and Simon - 1980 - Functional Analysis.pdf}
}

@article{seltzSolvingPopulationBalance2021,
  title = {Solving the Population Balance Equation for Non-Inertial Particles Dynamics Using Probability Density Function and Neural Networks: {{Application}} to a Sooting Flame},
  shorttitle = {Solving the Population Balance Equation for Non-Inertial Particles Dynamics Using Probability Density Function and Neural Networks},
  author = {Seltz, Andrea and Domingo, Pascale and Vervisch, Luc},
  year = {2021},
  month = jan,
  journal = {Physics of Fluids},
  volume = {33},
  number = {1},
  pages = {013311},
  issn = {1070-6631},
  doi = {10.1063/5.0031144},
  urldate = {2023-07-08},
  abstract = {Numerical modeling of non-inertial particles dynamics is usually addressed by solving a population balance equation (PBE). In addition to space and time, a discretization is required also in the particle-size space, covering a large range of variation controlled by strongly nonlinear phenomena. A novel approach is presented in which a hybrid stochastic/fixed-sectional method solving the PBE is used to train a combination of an artificial neural network (ANN) with a convolutional neural network (CNN) and recurrent long short-term memory artificial neural layers. The hybrid stochastic/fixed-sectional method decomposes the problem into the total number density and the probability density function of sizes, allowing for an accurate treatment of surface growth/loss. After solving for the transport of species and temperature, the input of the ANN is composed of the thermochemical parameters controlling the particle physics and of the increment in time. The input of the CNN is the shape of the particle size distribution (PSD) discretized in sections of size. From these inputs, in a flow simulation, the ANN\textendash CNN returns the PSD shape for the subsequent time step or a source term for the Eulerian transport of the particle size density. The method is evaluated in a canonical laminar premixed sooting flame of the literature, and for a given level of accuracy (i.e., a given discretization of the size space), a significant computing cost reduction is achieved (six times faster compared to a sectional method with ten sections and 30 times faster for 100 sections).},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Physics of Fluids/2021/Seltz et al_2021_Solving the population balance equation for non-inertial particles dynamics.pdf;/Users/steven/Zotero/storage/ALD7NR4F/Solving-the-population-balance-equation-for-non.html}
}

@article{singhChallengesOpportunitiesConcerning2022,
  title = {Challenges and Opportunities Concerning Numerical Solutions for Population Balances: A Critical Review},
  shorttitle = {Challenges and Opportunities Concerning Numerical Solutions for Population Balances},
  author = {Singh, Mehakpreet and Ranade, Vivek and Shardt, Orest and Matsoukas, Themis},
  year = {2022},
  month = sep,
  journal = {Journal of Physics A: Mathematical and Theoretical},
  volume = {55},
  number = {38},
  pages = {383002},
  publisher = {{IOP Publishing}},
  issn = {1751-8121},
  doi = {10.1088/1751-8121/ac8a42},
  urldate = {2023-07-08},
  abstract = {Population balance models are tools for the study of dispersed systems, such as granular materials, polymers, colloids and aerosols. They are applied with increasing frequency across a wide range of disciplines, including chemical engineering, aerosol physics, astrophysics, polymer science, pharmaceutical sciences, and mathematical biology. Population balance models are used to track particle properties and their changes due to aggregation, fragmentation, nucleation and growth, processes that directly affect the distribution of particle sizes. The population balance equation is an integro-partial differential equation whose domain is the line of positive real numbers. This poses challenges for the stability and accuracy of the numerical methods used to solve for size distribution function and in response to these challenges several different methodologies have been developed in the literature. This review provides a critical presentation of the state of the art in numerical approaches for solving these complex models with emphasis in the algorithmic details that distinguish each methodology. The review covers finite volume methods, Monte Carlo method and sectional methods; the method of moments, another important numerical methodology, is not covered in this review.},
  langid = {english},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Physics A Mathematical and Theoretical/2022/Singh et al_2022_Challenges and opportunities concerning numerical solutions for population.pdf}
}

@article{songSparseMultivariateFunctional2022,
  title = {Sparse Multivariate Functional Principal Component Analysis},
  author = {Song, Jun and Kim, Kyongwon},
  year = {2022},
  journal = {Stat},
  volume = {11},
  number = {1},
  pages = {e435},
  issn = {2049-1573},
  doi = {10.1002/sta4.435},
  urldate = {2023-09-15},
  abstract = {We introduce a sparse multivariate functional principal component analysis method by incorporating ideas from the group sparse maximum variance method to multivariate functional data. Our method can avoid the ``curse of dimensionality'' from a high-dimensional dataset and enjoy interpretability at the same time. In particular, our unsupervised method can capture important latent factors to explain variability of the dataset, which can induce a clear distinction between important variables in the principal components and unnecessary features based on the sparseness structure. Furthermore, our method can be applied to functional data from a multidimensional domain that hinges on different intervals. In the numerical experiment, we show that our method works well in both low- and high-dimensional multivariate functional data regardless of the number and the type of basis. We further apply our method to stock market data and electroencephalography data in an alcoholism study to demonstrate the theoretical result.},
  copyright = {\textcopyright{} 2021 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {functional principal component analysis,group sparse maximum variance method,multivariate functional data analysis},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Stat/2022/Song_Kim_2022_Sparse multivariate functional principal component analysis.pdf;/Users/steven/Zotero/storage/DACNDSUW/sta4.html}
}

@article{sotolongo-costaNonextensiveStatisticalModel2015,
  title = {A Non-Extensive Statistical Model for Time-Dependent Multiple Breakage Particle-Size Distribution},
  author = {{Sotolongo-Costa}, O. and {Gaggero-Sager}, L. M. and {Mora-Ramos}, M. E.},
  year = {2015},
  month = nov,
  journal = {Physica A: Statistical Mechanics and its Applications},
  volume = {438},
  pages = {74--80},
  issn = {0378-4371},
  doi = {10.1016/j.physa.2015.06.042},
  urldate = {2023-07-08},
  abstract = {A general formulation for the statistical description of time-dependent multiple particle breakage processes is presented in terms of a purposely constructed dimensionless quantity that contains the main physical magnitudes involved in the problem. The approach combines the Tsallis non-extensive entropy with a kinetic equation with fractionary index for the time evolution of the size/mass of the fragments. The obtained distribution function is tested by fitting some experimental reports. It is found that the better adjustment corresponds, in all cases, to values of the time index equal or below 0.6, whereas the parameter of nonextensivity ranks between 1 and 2, as previously reported in other studies involving some kind of fragmentation. The work could be the first example of a non-extensive maximum-entropy statistical description based on a purposely constructed dimensionless quantity, as well as of the derivation of a fragment size distribution function explicitly dependent on measurable system variables. As a result, the role of quantities such as viscosity, velocity gradient and others becomes explicit in the formulation.},
  langid = {english},
  keywords = {Multiple particle breakage,Nonextensive statistics,Time dependence},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/undefined/2015/Sotolongo-Costa et al. - 2015 - A non-extensive statistical model for time-depende.pdf;/Users/steven/Zotero/storage/Q52YSXMH/S0378437115006020.html}
}

@article{staniswalisNonparametricRegressionAnalysis1998,
  title = {Nonparametric {{Regression Analysis}} of {{Longitudinal Data}}},
  author = {Staniswalis, Joan G. and Lee, J. Jack},
  year = {1998},
  journal = {Journal of the American Statistical Association},
  volume = {93},
  number = {444},
  eprint = {2670055},
  eprinttype = {jstor},
  pages = {1403--1418},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0162-1459},
  doi = {10.2307/2670055},
  urldate = {2023-08-24},
  abstract = {Nonparametric methods are developed for estimating the dose effect when a response consists of correlated observations over time measured in a dose-response experiment. The methods can also be applied to data collected from a completely randomized design experiment. Methods are developed for the detection and description of the effects of dose, time, and their interaction. The methods allow for individual variation in the timing and number of observations. A generalization allowing baseline covariates to be incorporated is addressed. These results may be used in an exploratory fashion in the process of building a random-effects model for longitudinal data.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the American Statistical Association/1998/Staniswalis_Lee_1998_Nonparametric Regression Analysis of Longitudinal Data.pdf}
}

@article{tibshiraniEstimatingNumberClusters2001,
  title = {Estimating the Number of Clusters in a Data Set via the Gap Statistic},
  author = {Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
  year = {2001},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {63},
  number = {2},
  pages = {411--423},
  issn = {1467-9868},
  doi = {10.1111/1467-9868.00293},
  urldate = {2023-07-08},
  abstract = {We propose a method (the `gap statistic') for estimating the number of clusters (groups) in a set of data. The technique uses the output of any clustering algorithm (e.g. K-means or hierarchical), comparing the change in within-cluster dispersion with that expected under an appropriate reference null distribution. Some theory is developed for the proposal and a simulation study shows that the gap statistic usually outperforms other methods that have been proposed in the literature.},
  copyright = {2001 Royal Statistical Society},
  langid = {english},
  keywords = {Clustering,Groups,Hierarchy,Uniform distribution},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the Royal Statistical Society Series B (Statistical Methodology)/2001/Tibshirani et al_2001_Estimating the number of clusters in a data set via the gap statistic.pdf;/Users/steven/Zotero/storage/KU3F2Z9H/1467-9868.html}
}

@book{tsybakovIntroductionNonparametricEstimation2008,
  title = {Introduction to {{Nonparametric Estimation}}},
  author = {Tsybakov, Alexandre B.},
  year = {2008},
  month = oct,
  publisher = {{Springer Series in Statistics}},
  abstract = {Developed from lecture notes and ready to be used for a course on the graduate level, this concise text aims to introduce the fundamental concepts of nonparametric estimation theory while maintaining the exposition suitable for a first approach in the field.},
  googlebooks = {mwB8rUBsbqoC},
  isbn = {978-0-387-79052-7},
  langid = {english},
  keywords = {Business \& Economics / Econometrics,Computers / Artificial Intelligence / Computer Vision \& Pattern Recognition,Computers / Mathematical \& Statistical Software,Computers / Optical Data Processing,Mathematics / Discrete Mathematics,Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes,Technology \& Engineering / Electronics / General,Technology \& Engineering / Imaging Systems},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer Science & Business Media/2008/Tsybakov_2008_Introduction to Nonparametric Estimation.pdf}
}

@book{tufteVisualDisplayQuantitative2001,
  title = {The Visual Display of Quantitative Information},
  author = {Tufte, Edward R.},
  year = {2001},
  edition = {Second edition},
  publisher = {{Graphics Press}},
  address = {{Cheshire, Conn.}},
  abstract = {"This book deals with the theory and practice in the design of data graphics and makes the point that the most effective way to describe, explore, and summarize a set of numbers is to look at pictures of those numbers, through the use of statistical graphics, charts, and tables. It includes 250 illustrations of the best (and a few of the worst) statistical graphics, with detailed analysis of how to display data for precise, effective, quick analysis. Also offered is information on the design of the high-resolution displays, small multiples, editing and improving graphics, and the data-ink ratio. Time-series, relational graphics, data maps, multivariate designs, as well as detection of graphical deception: design variation vs. data variation, and sources of deception are discussed. Information on aesthetics and data graphical displays is included. The 2nd edition provides high-resolution color reproductions of the many graphics of William Playfair (1750-1800), adds color to other images where appropriate, and includes all the changes and corrections during the 17 printings of the 1st edition"--Publisher's description},
  isbn = {978-0-9613921-4-7},
  langid = {english},
  keywords = {Affichage (Technique),Art,Audio-visual materials,Audiovisual Aids,audiovisual materials,Authors' autographs (Provenance),bar graphs,bilder,Bildesemiologi,Chart,charts (graphic documents),{Charts, diagrams, etc},circular graphs,computer graphics,Computer graphics,Computer Graphics,Conception assist\'ee par ordinateur,Data Display,Diagramm,DISPLAY DEVICES,Documents audiovisuels,EDB,fine arts (discipline),forfatterskap,framstilling,grafikk,Grafische Darstellung,Grafisk design,Grafisk fremstilling,GRAPHIC ARTS,Graphiques,graphs,Graphs,Infographie,Information display systems,Kvantitative metoder,line graphs,M\'ethode graphique,Statistics,STATISTICS,Statistics as Topic,{Statistics Charts, diagrams, etc},Statistics Graphic methods,Statistik,Statistique,Statistique M\'ethodes graphiques,{Statistique Tableaux, graphiques, etc},Statistiques,Visualisering,Visualisierung,visuell,vitenskapelig,works of art},
  annotation = {OCLC: 46932988},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Graphics Press/2001/Tufte_2001_The visual display of quantitative information.pdf}
}

@article{wangNewMethodSolving2020,
  title = {A New Method for Solving Population Balance Equations Using a Radial Basis Function Network},
  author = {Wang, Kaiyuan and Yu, Suyuan and Peng, Wei},
  year = {2020},
  month = jun,
  journal = {Aerosol Science and Technology},
  volume = {54},
  number = {6},
  pages = {644--655},
  publisher = {{Taylor \& Francis}},
  issn = {0278-6826},
  doi = {10.1080/02786826.2019.1711358},
  urldate = {2023-07-08},
  abstract = {This study presents a new method for solving the population balance equation (PBE) for particle coagulation. The method introduces a radial basis function network to approximate the number density function. The approximate solution should satisfy the PBE at the collocation points in a continuous manner. The coagulation terms in the PBE are directly handled using the Gaussian quadrature techniques. The final solution is a bivariant analytical function of particle volume and time, which can be easily used in any subsequent calculation. Then the method is validated by comparing with analytical solutions and the sectional method for four numerical test problems. These problems are selected to vary in coagulation kernels and initial conditions. The comparative results show that the present method can accurately predict the time evolution of the number density function. Moreover, the computational efficiency of the present method is quite acceptable considering the high accuracy.Copyright \textcopyright{} 2020 American Association for Aerosol Research},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Aerosol Science and Technology/2020/Wang et al_2020_A new method for solving population balance equations using a radial basis.pdf}
}

@article{warmenhovenBivariateFunctionalPrincipal2019,
  title = {Bivariate Functional Principal Components Analysis: Considerations for Use with Multivariate Movement Signatures in Sports Biomechanics},
  shorttitle = {Bivariate Functional Principal Components Analysis},
  author = {Warmenhoven, John and Cobley, Stephen and Draper, Conny and Harrison, Andrew and Bargary, Norma and Smith, Richard},
  year = {2019},
  month = jan,
  journal = {Sports Biomechanics},
  volume = {18},
  number = {1},
  pages = {10--27},
  publisher = {{Routledge}},
  issn = {1476-3141},
  doi = {10.1080/14763141.2017.1384050},
  urldate = {2023-09-15},
  abstract = {Sporting performance is often investigated through graphical observation of key technical variables that are representative of whole movements. The presence of differences between athletes in such variables has led to terms such as movement signatures being used. These signatures can be multivariate (multiple time-series observed concurrently), and also be composed of variables measured relative to different scales. Analytical techniques from areas of statistics such as Functional Data Analysis (FDA) present a practical alternative for analysing multivariate signatures. When applied to concurrent bivariate time-series multivariate functional principal components analysis (referred to as bivariate fPCA or bfPCA in this paper) has demonstrated preliminary application in biomechanical contexts. Despite this, given the infancy of bfPCA in sports biomechanics there are still necessary considerations for its use with non-conventional or complex bivariate structures. This paper focuses on the application of bfPCA to the force-angle graph in on-water rowing, which is a bivariate structure composed of variables with different units. A normalisation approach is proposed to investigate and standardise differences in variability between the two variables. The results of bfPCA applied to the non-normalised data and normalised data are then compared. Considerations and recommendations for the application of bfPCA in this context are also provided.},
  pmid = {29125036},
  keywords = {biomechanics,FDA,rowing,statistics},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Sports Biomechanics/2019/Warmenhoven et al_2019_Bivariate functional principal components analysis.pdf}
}

@article{yaoFunctionalDataAnalysis2005,
  title = {Functional {{Data Analysis}} for {{Sparse Longitudinal Data}}},
  author = {Yao, Fang and M{\"u}ller, Hans-Georg and Wang, Jane-Ling},
  year = {2005},
  journal = {Journal of the American Statistical Association},
  volume = {100},
  number = {470},
  eprint = {27590579},
  eprinttype = {jstor},
  pages = {577--590},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0162-1459},
  urldate = {2023-08-17},
  abstract = {We propose a nonparametric method to perform functional principal components analysis for the case of sparse longitudinal data. The method aims at irregularly spaced longitudinal data, where the number of repeated measurements available per subject is small. In contrast, classical functional data analysis requires a large number of regularly spaced measurements per subject. We assume that the repeated measurements are located randomly with a random number of repetitions for each subject and are determined by an underlying smooth random (subject-specific) trajectory plus measurement errors. Basic elements of our approach are the parsimonious estimation of the covariance structure and mean function of the trajectories, and the estimation of the variance of the measurement errors. The eigenfunction basis is estimated from the data, and functional principal components score estimates are obtained by a conditioning step. This conditional estimation method is conceptually simple and straightforward to implement. A key step is the derivation of asymptotic consistency and distribution results under mild conditions, using tools from functional analysis. Functional data analysis for sparse longitudinal data enables prediction of individual smooth trajectories even if only one or few measurements are available for a subject. Asymptotic pointwise and simultaneous confidence bands are obtained for predicted individual trajectories, based on asymptotic distributions, for simultaneous bands under the assumption of a finite number of components. Model selection techniques, such as the Akaike information criterion, are used to choose the model dimension corresponding to the number of eigenfunctions in the model. The methods are illustrated with a simulation study, longitudinal CD4 data for a sample of AIDS patients, and time-course gene expression data for the yeast cell cycle.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the American Statistical Association/2005/Yao et al_2005_Functional Data Analysis for Sparse Longitudinal Data.pdf}
}

@article{zhangSparseDenseFunctional2016,
  title = {From Sparse to Dense Functional Data and Beyond},
  author = {Zhang, Xiaoke and Wang, Jane-Ling},
  year = {2016},
  month = oct,
  journal = {The Annals of Statistics},
  volume = {44},
  number = {5},
  pages = {2281--2321},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/16-AOS1446},
  urldate = {2023-08-24},
  abstract = {Nonparametric estimation of mean and covariance functions is important in functional data analysis. We investigate the performance of local linear smoothers for both mean and covariance functions with a general weighing scheme, which includes two commonly used schemes, equal weight per observation (OBS), and equal weight per subject (SUBJ), as two special cases. We provide a comprehensive analysis of their asymptotic properties on a unified platform for all types of sampling plan, be it dense, sparse or neither. Three types of asymptotic properties are investigated in this paper: asymptotic normality, \$L\^\{2\}\$ convergence and uniform convergence. The asymptotic theories are unified on two aspects: (1) the weighing scheme is very general; (2) the magnitude of the number \$N\_\{i\}\$ of measurements for the \$i\$th subject relative to the sample size \$n\$ can vary freely. Based on the relative order of \$N\_\{i\}\$ to \$n\$, functional data are partitioned into three types: non-dense, dense and ultra-dense functional data for the OBS and SUBJ schemes. These two weighing schemes are compared both theoretically and numerically. We also propose a new class of weighing schemes in terms of a mixture of the OBS and SUBJ weights, of which theoretical and numerical performances are examined and compared.},
  keywords = {\$L\^\{2\}\$ convergence,62G05,62G08,62G20,asymptotic normality,local linear smoothing,Uniform convergence,weighing schemes},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/The Annals of Statistics/2016/Zhang_Wang_2016_From sparse to dense functional data and beyond.pdf}
}

@article{zhangStatisticalInferencesFunctional2007,
  title = {Statistical Inferences for Functional Data},
  author = {Zhang, Jin-Ting and Chen, Jianwei},
  year = {2007},
  month = jul,
  journal = {The Annals of Statistics},
  volume = {35},
  number = {3},
  pages = {1052--1079},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/009053606000001505},
  urldate = {2023-07-08},
  abstract = {With modern technology development, functional data are being observed frequently in many scientific fields. A popular method for analyzing such functional data is ``smoothing first, then estimation.'' That is, statistical inference such as estimation and hypothesis testing about functional data is conducted based on the substitution of the underlying individual functions by their reconstructions obtained by one smoothing technique or another. However, little is known about this substitution effect on functional data analysis. In this paper this problem is investigated when the local polynomial kernel (LPK) smoothing technique is used for individual function reconstructions. We find that under some mild conditions, the substitution effect can be ignored asymptotically. Based on this, we construct LPK reconstruction-based estimators for the mean, covariance and noise variance functions of a functional data set and derive their asymptotics. We also propose a GCV rule for selecting good bandwidths for the LPK reconstructions. When the mean function also depends on some time-independent covariates, we consider a functional linear model where the mean function is linearly related to the covariates but the covariate effects are functions of time. The LPK reconstruction-based estimators for the covariate effects and the covariance function are also constructed and their asymptotics are derived. Moreover, we propose a L2-norm-based global test statistic for a general hypothesis testing problem about the covariate effects and derive its asymptotic random expression. The effect of the bandwidths selected by the proposed GCV rule on the accuracy of the LPK reconstructions and the mean function estimator is investigated via a simulation study. The proposed methodologies are illustrated via an application to a real functional data set collected in climatology.},
  keywords = {62G07,62G10,62J12,Asymptotic Gaussian process,Asymptotic normal distribution,functional data,hypothesis test,local polynomial smoothing,nonparametric estimation,reconstructed individual functions,root-n consistent},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/The Annals of Statistics/2007/Zhang_Chen_2007_Statistical inferences for functional data.pdf}
}
