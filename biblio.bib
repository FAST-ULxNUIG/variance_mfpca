@book{abramowitzHandbookMathematicalFunctions1965,
  title = {Handbook of {{Mathematical Functions}}: {{With Formulas}}, {{Graphs}}, and {{Mathematical Tables}}},
  shorttitle = {Handbook of {{Mathematical Functions}}},
  author = {Abramowitz, Milton and Stegun, Irene A.},
  year = {1965},
  month = jan,
  publisher = {{Courier Corporation}},
  abstract = {Vast compendium - 29 sets of tables, some to as high as 20 places.},
  googlebooks = {MtU8uP7XMvoC},
  isbn = {978-0-486-61272-0},
  langid = {english},
  keywords = {Mathematics / Functional Analysis,Mathematics / General},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Courier Corporation/1965/Abramowitz_Stegun_1965_Handbook of Mathematical Functions.pdf}
}

@article{basMathematicalModellingGranola2011,
  title = {Mathematical Modelling of Granola Breakage during Pipe Pneumatic Conveying},
  author = {Ba{\c s}, Nur{\c s}in and Pathare, Pankaj B. and Catak, Muammer and Fitzpatrick, John J. and Cronin, Kevin and Byrne, Edmond P.},
  year = {2011},
  month = jan,
  journal = {Powder Technology},
  series = {9th {{International Symposium}} on {{Agglomeration}} and 4th {{International Granulation Workshop}}, 2009},
  volume = {206},
  number = {1},
  pages = {170--176},
  issn = {0032-5910},
  doi = {10.1016/j.powtec.2010.06.015},
  urldate = {2023-07-07},
  abstract = {Granola is a baked aggregated food product which serves as a breakfast cereal or snack consisting of oats, cereals, nuts and honey. Particle breakage of aggregated granola can occur during conveying as product is transferred as part of the production process on its way to packaging. Such breakage occurs as a result of particle\textendash particle and particle\textendash wall collisions with the conveying equipment. In this work, a population balance model is developed to describe the breakage of granola as it is conveyed through a pneumatic conveying pipeline rig. The model incorporates the influence of conveying pressure, exposure time and pipeline geometry, and is also related to parameters associated with aggregate formation such as granulator mixing speed and time. The aggregates were formed in a high shear granulator subject to impeller agitation of 300rpm for 9min and were then propelled through a pipeline with a 90\textdegree{} bend at a number of different flow rates. Trials were carried out by applying compressed air at pressures of 200kPa, 300kPa and 400kPa while the aggregates were subjected to a number of recycles through the rig. Modelling of this breakage process was achieved by constructing the population balance equations (PBEs) in the form of a mass balance on the granola aggregates. The solutions to the PBEs were obtained by means of discretization through the application of the Markov chain method. When the size range of the system was divided into an appropriate number of states, the Markov chain method for the population balances exhibited a reasonable approximation for predicting the particle size distribution (PSD) over time particularly during the initial rig cycles.},
  langid = {english},
  keywords = {Breakage,Conveying,Markov chains,Population balance modelling},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Powder Technology/2011/Ba≈ü et al_2011_Mathematical modelling of granola breakage during pipe pneumatic conveying.pdf;/Users/steven/Zotero/storage/JZTXBPSM/S0032591010003141.html}
}

@article{berthiauxApplicationTheoryMarkov2005,
  title = {Application of the Theory of {{Markov}} Chains to Model Different Processes in Particle Technology},
  author = {Berthiaux, Henri and Mizonov, Vadim and Zhukov, Vladimir},
  year = {2005},
  month = sep,
  journal = {Powder Technology},
  series = {4th {{French Meeting}} on {{Powder Science}} and {{Technology}}},
  volume = {157},
  number = {1},
  pages = {128--137},
  issn = {0032-5910},
  doi = {10.1016/j.powtec.2005.05.019},
  urldate = {2023-07-08},
  abstract = {The essence of almost all processes with participation of particulate solids is similar: it is a transformation of a particle property, or properties. This suggests that a unified basis for examining the changes of this property with (for example) time, may be derived. In this paper, the general strategy of building the Markov chain models and computational analysis of characteristics of a process is described, and some examples of application of the approach to model grinding, classification, grinding with internal classification, mixing, agglomeration, etc, are shown. The use of multidimensional models to consider simultaneously different properties is emphasised. The approach also allows taking into account non-linear phenomena, which are very typical of particulate processes but are very seldom considered in usual models.},
  langid = {english},
  keywords = {Markov chains,Particle technology,Transition matrix},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Powder Technology/2005/Berthiaux et al. - 2005 - Application of the theory of Markov chains to mode.pdf;/Users/steven/Zotero/storage/2MFSKMNF/S0032591005002354.html}
}

@article{bessePrincipalComponentsAnalysis1986,
  title = {Principal Components Analysis of Sampled Functions},
  author = {Besse, Philippe and Ramsay, J. O.},
  year = {1986},
  month = jun,
  journal = {Psychometrika},
  volume = {51},
  number = {2},
  pages = {285--311},
  issn = {1860-0980},
  doi = {10.1007/BF02293986},
  urldate = {2023-07-08},
  abstract = {This paper describes a technique for principal components analysis of data consisting ofn functions each observed atp argument values. This problem arises particularly in the analysis of longitudinal data in which some behavior of a number of subjects is measured at a number of points in time. In such cases information about the behavior of one or more derivatives of the function being sampled can often be very useful, as for example in the analysis of growth or learning curves. It is shown that the use of derivative information is equivalent to a change of metric for the row space in classical principal components analysis. The reproducing kernel for the Hilbert space of functions plays a central role, and defines the best interpolating functions, which are generalized spline functions. An example is offered of how sensitivity to derivative information can reveal interesting aspects of the data.},
  langid = {english},
  keywords = {Green's functions,Hilbert space of functions,interpolation,reproducing kernel,smoothing,spline functions},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Psychometrika/1986/Besse and Ramsay - 1986 - Principal components analysis of sampled functions.pdf}
}

@article{catakDiscreteSolutionBreakage2010,
  title = {Discrete {{Solution}} of the {{Breakage Equation Using Markov Chains}}},
  author = {Catak, Muammer and Bas, Nursin and Cronin, Kevin and Fitzpatrick, John J. and Byrne, Edmond P.},
  year = {2010},
  month = sep,
  journal = {Industrial \& Engineering Chemistry Research},
  volume = {49},
  number = {17},
  pages = {8248--8257},
  publisher = {{American Chemical Society}},
  issn = {0888-5885},
  doi = {10.1021/ie100216g},
  urldate = {2023-07-08},
  abstract = {Analytical solution of population balance equations (PBEs) may be impossible except for some simple cases. In the literature there are a number of methods to solve PBEs including discrete methods, Monte Carlo simulation, and method of moments. In this paper, the Markov chain is presented as a discrete solution for a population balance equation of a breakage process for determining the particle size distribution (PSD) over time. The transition matrix P, which is the key operator of a Markov chain, is built using breakage equations. Thereafter, from calculating transition matrix, P, the particle size distribution of the system is easily evaluated using the Markov chain. According to simulation results, if the size range of the system is divided into a sufficient number of states and an appropriate transition time step was chosen, then results from the Markov chain are in agreement with the analytical solution of PBEs governed by the same breakage functions. In addition to theoretical illustration, the Markov theory was employed to model the breakage process of aggregated food products passing through a pneumatic conveying pipeline rig.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Industrial & Engineering Chemistry Research/2010/Catak et al. - 2010 - Discrete Solution of the Breakage Equation Using M.pdf}
}

@article{chiouMultivariateFunctionalPrincipal2014,
  title = {Multivariate {{Functional Principal Component Analysis}}: {{A Normalization Approach}}},
  shorttitle = {Multivariate {{Functional Principal Component Analysis}}},
  author = {Chiou, Jeng-Min and Chen, Yu-Ting and Yang, Ya-Fang},
  year = {2014},
  journal = {Statistica Sinica},
  volume = {24},
  number = {4},
  eprint = {24310959},
  eprinttype = {jstor},
  pages = {1571--1596},
  publisher = {{Institute of Statistical Science, Academia Sinica}},
  issn = {1017-0405},
  urldate = {2023-07-08},
  abstract = {We propose an extended version of the classical Karhunen-Lo\`eve expansion of a multivariate random process, termed a normalized multivariate functional principal component (mFPCn) representation. This takes variations between the components of the process into account and takes advantage of component dependencies through the pairwise cross-covariance functions. This approach leads to a single set of multivariate functional principal component scores, which serve well as a proxy for multivariate functional data. We derive the consistency properties for the estimates of the mFPCn, and the asymptotic distributions for statistical inferences. We illustrate the finite sample performance of this approach through the analysis of a traffic flow data set, including an application to clustering and a simulation study. The mFPCn approach serves as a basic and useful statistical tool for multivariate functional data analysis.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Statistica Sinica/2014/Chiou et al_2014_Multivariate Functional Principal Component Analysis.pdf}
}

@article{clevelandRobustLocallyWeighted1979,
  title = {Robust {{Locally Weighted Regression}} and {{Smoothing Scatterplots}}},
  author = {Cleveland, William S.},
  year = {1979},
  journal = {Journal of the American Statistical Association},
  volume = {74},
  number = {368},
  eprint = {2286407},
  eprinttype = {jstor},
  pages = {829--836},
  publisher = {{[American Statistical Association, Taylor \& Francis, Ltd.]}},
  issn = {0162-1459},
  doi = {10.2307/2286407},
  urldate = {2023-07-08},
  abstract = {The visual information on a scatterplot can be greatly enhanced, with little additional cost, by computing and plotting smoothed points. Robust locally weighted regression is a method for smoothing a scatterplot, (x\textsubscript{i}, y\textsubscript{i}), i = 1, {$\cdots$}, n, in which the fitted value at x\textsubscript{k} is the value of a polynomial fit to the data using weighted least squares, where the weight for (x\textsubscript{i}, y\textsubscript{i}) is large if x\textsubscript{i} is close to x\textsubscript{k} and small if it is not. A robust fitting procedure is used that guards against deviant points distorting the smoothed points. Visual, computational, and statistical issues of robust locally weighted regression are discussed. Several examples, including data on lead intoxication, are used to illustrate the methodology.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the American Statistical Association/1979/Cleveland_1979_Robust Locally Weighted Regression and Smoothing Scatterplots.pdf}
}

@article{gonzalezRepresentingFunctionalData2010,
  title = {Representing Functional Data in Reproducing {{Kernel Hilbert Spaces}} with Applications to Clustering and Classification},
  author = {Gonz{\'a}lez, Javier and Mu{\~n}oz, Alberto},
  year = {2010},
  month = may,
  journal = {DES - Working Papers. Statistics and Econometrics. WS},
  number = {ws102713},
  publisher = {{Universidad Carlos III de Madrid. Departamento de Estad\'istica}},
  urldate = {2023-07-08},
  abstract = {Functional data are difficult to manage for many traditional statistical techniques given their very high (or intrinsically infinite) dimensionality. The reason is that functional data are essentially functions and most algorithms are designed to work with (low) finite-dimensional vectors. Within this context we propose techniques to obtain finitedimensional representations of functional data. The key idea is to consider each functional curve as a point in a general function space and then project these points onto a Reproducing Kernel Hilbert Space with the aid of Regularization theory. In this work we describe the projection method, analyze its theoretical properties and propose a model selection procedure to select appropriate Reproducing Kernel Hilbert spaces to project the functional data.},
  langid = {english},
  keywords = {Functional data},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/DES - Working Papers. Statistics and Econometrics. WS/2010/Gonz√°lez_Mu√±oz_2010_Representing functional data in reproducing Kernel Hilbert Spaces with.pdf;/Users/steven/Zotero/storage/U9SIH6GN/ws102713.html}
}

@article{happ-kurzObjectOrientedSoftwareFunctional2020,
  title = {Object-{{Oriented Software}} for {{Functional Data}}},
  author = {{Happ-Kurz}, Clara},
  year = {2020},
  month = apr,
  journal = {Journal of Statistical Software},
  volume = {93},
  pages = {1--38},
  issn = {1548-7660},
  doi = {10.18637/jss.v093.i05},
  urldate = {2023-07-31},
  abstract = {This paper introduces the funData R package as an object-oriented implementation of functional data. It implements a unified framework for dense univariate and multivariate functional data on one- and higher dimensional domains as well as for irregular functional data. The aim of this package is to provide a user-friendly, self-contained core toolbox for functional data, including important functionalities for creating, accessing and modifying functional data objects, that can serve as a basis for other packages. The package further contains a full simulation toolbox, which is a useful feature when implementing and testing new methodological developments. Based on the theory of object-oriented data analysis, it is shown why it is natural to implement functional data in an object-oriented manner. The classes and methods provided by funData are illustrated in many examples using two freely available datasets. The MFPCA package, which implements multivariate functional principal component analysis, is presented as an example for an advanced methodological package that uses the funData package as a basis, including a case study with real data. Both packages are publicly available on GitHub and the Comprehensive R Archive Network.},
  copyright = {Copyright (c) 2020 Clara Happ-Kurz},
  langid = {english},
  keywords = {functional data analysis,functional principal component analysis,multivariate functional data,object orientation,simulation},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Statistical Software/2020/Happ-Kurz_2020_Object-Oriented Software for Functional Data.pdf}
}

@article{happMultivariateFunctionalPrincipal2018,
  title = {Multivariate {{Functional Principal Component Analysis}} for {{Data Observed}} on {{Different}} ({{Dimensional}}) {{Domains}}},
  author = {Happ, Clara and Greven, Sonja},
  year = {2018},
  month = apr,
  journal = {Journal of the American Statistical Association},
  volume = {113},
  number = {522},
  pages = {649--659},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.2016.1273115},
  urldate = {2023-07-08},
  abstract = {Existing approaches for multivariate functional principal component analysis are restricted to data on the same one-dimensional interval. The presented approach focuses on multivariate functional data on different domains that may differ in dimension, such as functions and images. The theoretical basis for multivariate functional principal component analysis is given in terms of a Karhunen\textendash Lo\`eve Theorem. For the practically relevant case of a finite Karhunen\textendash Lo\`eve representation, a relationship between univariate and multivariate functional principal component analysis is established. This offers an estimation strategy to calculate multivariate functional principal components and scores based on their univariate counterparts. For the resulting estimators, asymptotic results are derived. The approach can be extended to finite univariate expansions in general, not necessarily orthonormal bases. It is also applicable for sparse functional data or data with measurement error. A flexible R implementation is available on CRAN. The new method is shown to be competitive to existing approaches for data observed on a common one-dimensional domain. The motivating application is a neuroimaging study, where the goal is to explore how longitudinal trajectories of a neuropsychological test score covary with FDG-PET brain scans at baseline. Supplementary material, including detailed proofs, additional simulation results, and software is available online.},
  keywords = {Dimension reduction,Functional data analysis,Image analysis,Multivariate functional data},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the American Statistical Association/2018/Happ and Greven - 2018 - Multivariate Functional Principal Component Analys_supp.pdf;/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the American Statistical Association/2018/Happ and Greven - 2018 - Multivariate Functional Principal Component Analys.pdf}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-84858-7},
  urldate = {2023-07-07},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2009/Hastie et al_2009_The Elements of Statistical Learning_outline.pdf;/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2009/Hastie et al. - 2009 - The Elements of Statistical Learning.pdf}
}

@article{hillStatisticsMultipleParticle1996,
  title = {Statistics of Multiple Particle Breakage},
  author = {Hill, Priscilla J. and Ng, Ka M.},
  year = {1996},
  journal = {AIChE Journal},
  volume = {42},
  number = {6},
  pages = {1600--1611},
  issn = {1547-5905},
  doi = {10.1002/aic.690420611},
  urldate = {2023-07-08},
  abstract = {A method for generating theoretical breakage distribution functions for multiple particle breakage is presented. It starts with the joint probability function that accounts for all the child particles; it is then reduced to the marginal probability function commonly used in the breakage equation. This method is flexible enough to allow the user to choose the number of child particles and the functional form to be used. The method is demonstrated with both product and summation functions with a power-law form. To facilitate the use of these theoretical functions for statistical analyses, a companion discretized breakage equation is developed. The new equation guarantees the conservation of mass and correct prediction of the total number of particles despite discretization. It is easy to use because it is a set of ordinary differential equations and applicable to both equal-size and geometric-size intervals. Simulation results show that different breakage distribution functions coupled with different breakage rates can produce almost indistinguishable particle-size distributions, signifying the need for further work in this area.},
  copyright = {Copyright \textcopyright{} 1996 American Institute of Chemical Engineers},
  langid = {english},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/AIChE Journal/1996/Hill and Ng - 1996 - Statistics of multiple particle breakage.pdf;/Users/steven/Zotero/storage/6H7B9A22/aic.html}
}

@article{jacquesModelbasedClusteringMultivariate2014,
  title = {Model-Based Clustering for Multivariate Functional Data},
  author = {Jacques, Julien and Preda, Cristian},
  year = {2014},
  month = mar,
  journal = {Computational Statistics \& Data Analysis},
  volume = {71},
  pages = {92--106},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2012.12.004},
  urldate = {2023-07-08},
  abstract = {The first model-based clustering algorithm for multivariate functional data is proposed. After introducing multivariate functional principal components analysis (MFPCA), a parametric mixture model, based on the assumption of normality of the principal component scores, is defined and estimated by an EM-like algorithm. The main advantage of the proposed model is its ability to take into account the dependence among curves. Results on simulated and real datasets show the efficiency of the proposed method.},
  langid = {english},
  keywords = {Density approximation,EM-algorithm,Model-based clustering,Multivariate functional data,Multivariate functional principal component analysis},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Computational Statistics & Data Analysis/2014/Jacques_Preda_2014_Model-based clustering for multivariate functional data.pdf;/Users/steven/Zotero/storage/8GDK5ZI4/S0167947312004380.html}
}

@book{karhunenUeberLineareMethoden1947,
  title = {{\"Uber lineare Methoden in der Wahrscheinlichkeitsrechnung}},
  author = {Karhunen, Kari},
  year = {1947},
  series = {{Suomalaisen Tiedeakatemian toimituksia}},
  number = {ARRAY(0x55c9032fd4e0)},
  publisher = {{Zugl.: Helsinki, Univ., Diss., 1947}},
  address = {{Helsinki}},
  langid = {german}
}

@article{kastnerBayesianParameterEstimation2013,
  title = {Bayesian Parameter Estimation for a Jet-Milling Model Using {{Metropolis}}\textendash{{Hastings}} and {{Wang}}\textendash{{Landau}} Sampling},
  author = {Kastner, Catharine A. and Braumann, Andreas and Man, Peter L. W. and Mosbach, Sebastian and Brownbridge, George P. E. and Akroyd, Jethro and Kraft, Markus and Himawan, Chrismono},
  year = {2013},
  month = feb,
  journal = {Chemical Engineering Science},
  volume = {89},
  pages = {244--257},
  issn = {0009-2509},
  doi = {10.1016/j.ces.2012.11.027},
  urldate = {2023-07-08},
  abstract = {Bayesian parameter estimates for a computationally expensive multi-response jet-milling model are computed using the Metropolis\textendash Hastings and Wang\textendash Landau Markov Chain Monte Carlo sampling algorithms. The model is accompanied by data obtained from 74 experiments at different process settings which is used to estimate the model parameters. The experimentally measured quantities are the 10th, 50th and 90th quantiles of the resulting particle size distributions. Parameter estimation is performed on a population balance jet-milling model composed of three subprocesses: jet expansion, milling and classification. The model contains eight parameters requiring estimation and can compute the same quantities that are determined in the experiments. As the model is computationally expensive to solve, the sampling algorithms are applied to a surrogate model to establish algorithm specific parameters and to obtain model parameter estimates. The resulting parameter estimates are given with a discussion of their reliability and the observed behaviour of the two sampling algorithms. Comparison of the autocorrelation function between samples generated by the two algorithms shows that the Wang\textendash Landau algorithm exhibits more rapid decay. Trace plots of the parameter samples from the two algorithms appear to be analogous and encourage the supposition that the Markov Chains have converged to the distribution of interest. One- and two-dimensional density plots indicate a unimodal distribution for all parameters, which suggests that the obtained estimates are unique. The two-dimensional density plots also suggest correlation between at least two of the model parameters. The realised distribution generated by both algorithms produced consistent results and demonstrated similar behaviour. For the application considered in this work, the Wang\textendash Landau algorithm is found to exhibit superior performance with respect to the correlation and equivalent performance in all other respects.},
  langid = {english},
  keywords = {Markov chain Monte Carlo,Mathematical modelling,Parameter identification,Particulate processing,Population balance,Wang\textendash Landau},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Chemical Engineering Science/2013/Kastner et al. - 2013 - Bayesian parameter estimation for a jet-milling mo.pdf;/Users/steven/Zotero/storage/HHMPLUFA/S000925091200677X.html}
}

@book{loeveFonctionsAleatoiresSecond1965,
  title = {{Fonctions al\'eatoires du second ordre...}},
  author = {Lo{\`e}ve, Michel},
  year = {1965},
  googlebooks = {Was5XwAACAAJ},
  langid = {french}
}

@article{longEstimatingReactionParameters2022,
  title = {Estimating Reaction Parameters in Mechanism-Enabled Population Balance Models of Nanoparticle Size Distributions: {{A Bayesian}} Inverse Problem Approach},
  shorttitle = {Estimating Reaction Parameters in Mechanism-Enabled Population Balance Models of Nanoparticle Size Distributions},
  author = {Long, Danny K. and Bangerth, Wolfgang and Handwerk, Derek R. and Whitehead, Christopher B. and Shipman, Patrick D. and Finke, Richard G.},
  year = {2022},
  journal = {Journal of Computational Chemistry},
  volume = {43},
  number = {1},
  pages = {43--56},
  issn = {1096-987X},
  doi = {10.1002/jcc.26770},
  urldate = {2023-07-08},
  abstract = {In order to quantitatively predict nano- as well as other particle-size distributions, one needs to have both a mathematical model and estimates of the parameters that appear in these models. Here, we show how one can use Bayesian inversion to obtain statistical estimates for the parameters that appear in recently derived mechanism-enabled population balance models (ME-PBM) of nanoparticle growth. The Bayesian approach addresses the question of ``how well do we know our parameters, along with their uncertainties?.'' The results reveal that Bayesian inversion statistical analysis on an example, prototype nanoparticle formation system allows one to estimate not just the most likely rate constants and other parameter values, but also their SDs, confidence intervals, and other statistical information. Moreover, knowing the reliability of the mechanistic model's parameters in turn helps inform one about the reliability of the proposed mechanism, as well as the reliability of its predictions. The paper can also be seen as a tutorial with the additional goal of achieving a ``Gold Standard'' Bayesian inversion ME-PBM benchmark that others can use as a control to check their own use of this methodology for other systems of interest throughout nature. Overall, the results provide strong support for the hypothesis that there is substantial value in using a Bayesian inversion methodology for parameter estimation in particle formation systems.},
  copyright = {\textcopyright{} 2021 Wiley Periodicals LLC.},
  langid = {english},
  keywords = {Bayesian inversion,kinetics and mechanism,nanoparticles,nucleation and growth,particle size distribution,population balance modeling},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Computational Chemistry/2022/Long et al. - 2022 - Estimating reaction parameters in mechanism-enable.pdf}
}

@article{martinezrodriguezParticleAgglomerationFlows2022,
  title = {Particle Agglomeration in Flows: {{Fast}} Data-Driven Spatial Decomposition Algorithm for {{CFD}} Simulations},
  shorttitle = {Particle Agglomeration in Flows},
  author = {Mart{\'i}nez Rodr{\'i}guez, Kerlyns and Bossy, Mireille and Henry, Christophe},
  year = {2022},
  month = apr,
  journal = {International Journal of Multiphase Flow},
  volume = {149},
  pages = {103962},
  issn = {0301-9322},
  doi = {10.1016/j.ijmultiphaseflow.2021.103962},
  urldate = {2023-07-08},
  abstract = {Computational fluid dynamics simulations in practical industrial/environmental cases often involve non-homogeneous concentrations of particles. In Euler\textendash Lagrange simulations, this can induce the propagation of numerical error when the number of collision/agglomeration events is computed using mean-field approaches. In fact, mean-field statistical collision models allow to sample the number of collision events using a priori information on the frequency of collisions (the collision kernel). Yet, since such methods often rely on the mesh used for the Eulerian simulation of the fluid phase, the particle number concentration within a given cell might not be homogeneous, leading to numerical errors. In this article, we apply the data-driven spatial decomposition (D2SD) algorithm to control such error in simulations of particle agglomeration. Significant improvements are made to design a fast D2SD version, minimising the additional computational cost by developing re-meshing criteria. Through the application to some practical simulation cases, we show the importance of splitting the domain when computing agglomeration events in Euler/Lagrange simulations, so that within each elementary cell there is a spatially uniform distribution of particles.},
  langid = {english},
  keywords = {Agglomeration,Computational Fluid Dynamics (CFD),Mesh-independence,Particle-based mesh,Particle-laden flows,Population Balance Equation (PBE)},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/International Journal of Multiphase Flow/2022/Mart√≠nez Rodr√≠guez et al_2022_Particle agglomeration in flows.pdf;/Users/steven/Zotero/storage/LTFAYIT3/S0301932221003578.html}
}

@techreport{mohajerComparisonGapStatistic2010,
  type = {{{workingPaper}}},
  title = {A Comparison of {{Gap}} Statistic Definitions with and without Logarithm Function},
  author = {Mohajer, Mojgan and Englmeier, Karl-Hans and Schmid, Volker J.},
  year = {2010},
  month = dec,
  volume = {96},
  doi = {10.5282/ubm/epub.11920},
  urldate = {2023-07-08},
  abstract = {The Gap statistic is a standard method for determining the number of clusters in a set of data. The Gap statistic standardizes the graph of \$\textbackslash log(W\_\{k\})\$, where \$W\_\{k\}\$ is the within-cluster dispersion, by comparing it to its expectation under an appropriate null reference distribution of the data. We suggest to use \$W\_\{k\}\$ instead of \$\textbackslash log(W\_\{k\})\$, and to compare it to the expectation of \$W\_\{k\}\$ under a null reference distribution. In fact, whenever a number fulfills the original Gap statistic inequality, this number also fulfills the inequality of a Gap statistic using \$W\_\{k\}\$, but not \textbackslash textit\{vice versa\}. The two definitions of the Gap function are evaluated on several simulated data set and on a real data of DCE-MR images.},
  langid = {english},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/undefined/2010/Mohajer et al_2010_A comparison of Gap statistic definitions with and without logarithm function.pdf;/Users/steven/Zotero/storage/Y3IPPS59/11920.html}
}

@article{mouraEstimationParametersSelection2022,
  title = {Estimation {{Of Parameters And Selection Of Models Applied To Population Balance Dynamics Via Approximate Bayesian Computational}}},
  author = {Moura, Carlos Henrique and Viegas, Bruno Marques and Tavares, Maria and Macedo, Emanuel and Estumano, Diego Cardoso},
  year = {2022},
  month = may,
  journal = {Journal of Heat and Mass Transfer Research},
  volume = {9},
  number = {1},
  pages = {53--64},
  publisher = {{Semnan University}},
  issn = {2345-508X},
  doi = {10.22075/jhmtr.2022.25186.1361},
  urldate = {2023-07-08},
  abstract = {Population balance models mathematically describe the particle size distribution based on modeling physical phenomena that influence the distribution, such as aggregation, growth, and breakage. Due to the wide range of mechanisms present, several models are presented in the literature since several hypotheses are considered. In the current work, the Approximate Bayesian Computational statistical technique was used to select four different models of population balance and estimate their parameters. Three strategies were applied to the drawing of parameters, evaluating the correlation between the parameters of the models. An adaptive tolerance in each population and a stopping criterion, based on Morozov's uncertainty principle, were used for the algorithm. The technique obtained reasonable estimates for the phenomenological rates of the models. The algorithm correctly selected the model used for generating measurements, and the three draw strategies demonstrated good applicability. The results obtained showed that the algorithm presented accuracy and precision in estimating the parameters and properly selected the models analyzed.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Heat and Mass Transfer Research/2022/Moura et al_2022_Estimation Of Parameters And Selection Of Models Applied To Population Balance.pdf}
}

@article{mouraParameterEstimationPopulation2021,
  title = {Parameter {{Estimation}} in {{Population Balance}} through {{Bayesian}} ‚Äé{{Technique Markov Chain Monte Carlo}}},
  author = {Moura, Carlos H. R. and Viegas, Bruno M. and Tavares, Maria R. M. and Mac{\^e}do, Emanuel N. and Estumano, Diego C. and Quaresma, Jo{\~a}o N. N.},
  year = {2021},
  month = apr,
  journal = {Journal of Applied and Computational Mechanics},
  volume = {7},
  number = {2},
  pages = {890--901},
  publisher = {{Shahid Chamran University of Ahvaz}},
  issn = {2383-4536},
  doi = {10.22055/jacm.2021.35741.2725},
  urldate = {2023-07-08},
  abstract = {In this work, the Markov Chain Monte Carlo is applied to estimate parameters that represent mechanisms that describe particles' dynamics in particulate systems from the literature's proposed models. Initially, the reduced sensitivity coefficient is evaluated to verify which parameters could be estimated simultaneously. The technique is then applied to estimate the models' parameters in different numerical scenarios to determine the rates that influence population dynamics. After the analyzes are performed, the estimates show good precision, accuracy, and a good fit between the measured and estimated state variables. The results show that the Markov chain Monte Carlo can determine the rates of population balance phenomenon.},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Applied and Computational Mechanics/2021/Moura et al_2021_Parameter Estimation in Population Balance through Bayesian Technique Markov.pdf}
}

@article{pattersonStochasticWeightedParticle2011,
  title = {Stochastic Weighted Particle Methods for Population Balance Equations},
  author = {Patterson, Robert I. A. and Wagner, Wolfgang and Kraft, Markus},
  year = {2011},
  month = aug,
  journal = {Journal of Computational Physics},
  volume = {230},
  number = {19},
  pages = {7456--7472},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2011.06.011},
  urldate = {2023-07-08},
  abstract = {A class of coagulation weight transfer functions is constructed, each member of which leads to a stochastic particle algorithm for the numerical treatment of population balance equations. These algorithms are based on systems of weighted computational particles and the weight transfer functions are constructed such that the number of computational particles does not change during coagulation events. The algorithms also facilitate the simulation of physical processes that change single particles, such as growth, or other surface reactions. Four members of the algorithm family have been numerically validated by comparison to analytic solutions to simple problems. Numerical experiments have been performed for complex laminar premixed flame systems in which members of the class of stochastic weighted particle methods were compared to each other and to a direct simulation algorithm. Two of the weighted algorithms have been shown to offer performance advantages over the direct simulation algorithm in situations where interest is focused on the larger particles in a system. The extent of this advantage depends on the particular system and on the quantities of interest.},
  langid = {english},
  keywords = {Coagulation,Markov chain,Monte Carlo,Population balance,Soot,Weighted particle},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Computational Physics/2011/Patterson et al. - 2011 - Stochastic weighted particle methods for populatio.pdf;/Users/steven/Zotero/storage/FCX6W3CG/S0021999111003603.html}
}

@article{ramkrishnaPopulationBalanceModeling2014,
  title = {Population Balance Modeling: Current Status and Future Prospects},
  shorttitle = {Population Balance Modeling},
  author = {Ramkrishna, Doraiswami and Singh, Meenesh R.},
  year = {2014},
  journal = {Annual Review of Chemical and Biomolecular Engineering},
  volume = {5},
  pages = {123--146},
  issn = {1947-5438},
  doi = {10.1146/annurev-chembioeng-060713-040241},
  abstract = {Population balance modeling is undergoing phenomenal growth in its applications, and this growth is accompanied by multifarious reviews. This review aims to fortify the model's fundamental base, as well as point to a variety of new applications, including modeling of crystal morphology, cell growth and differentiation, gene regulatory processes, and transfer of drug resistance. This is accomplished by presenting the many faces of population balance equations that arise in the foregoing applications.},
  langid = {english},
  pmid = {24606333},
  keywords = {Algorithms,biofilm growth,Cell Physiological Phenomena,crystal morphology,Crystallization,Gene Expression Regulation,gene regulatory processes,{Models, Theoretical},personalized medicine,Precision Medicine,stem cell differentiation,stochastic internal coordinates,Stochastic Processes,Tissue Engineering},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Annual Review of Chemical and Biomolecular Engineering/2014/Ramkrishna and Singh - 2014 - Population balance modeling current status and fu.pdf}
}

@book{ramsayFunctionalDataAnalysis2005,
  title = {Functional {{Data Analysis}}},
  author = {Ramsay, J. O. and Silverman, B. W.},
  year = {2005},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/b98888},
  urldate = {2023-07-07},
  isbn = {978-0-387-40080-8 978-0-387-22751-1},
  langid = {english},
  keywords = {correlation,data analysis,Fitting,Generalized linear model,linear regression},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2005/Ramsay and Silverman - 2005 - Functional Data Analysis.pdf;/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Springer/2005/Ramsay_Silverman_2005_Functional Data Analysis_outline.pdf}
}

@book{reedFunctionalAnalysis1980,
  title = {Functional {{Analysis}}},
  author = {Reed, Michael and Simon, Barry},
  year = {1980},
  month = jan,
  publisher = {{Academic Press}},
  address = {{New York}},
  abstract = {This book is the first of a multivolume series devoted to an exposition of functional analysis methods in modern mathematical physics. It describes the fundamental principles of functional analysis and is essentially self-contained, although there are occasional references to later volumes. We have included a few applications when we thought that they would provide motivation for the reader. Later volumes describe various advanced topics in functional analysis and give numerous applications in classical physics, modern physics, and partial differential equations.},
  isbn = {978-0-12-585050-6},
  langid = {english},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Academic Press/1980/Reed and Simon - 1980 - Functional Analysis.pdf}
}

@article{seltzSolvingPopulationBalance2021,
  title = {Solving the Population Balance Equation for Non-Inertial Particles Dynamics Using Probability Density Function and Neural Networks: {{Application}} to a Sooting Flame},
  shorttitle = {Solving the Population Balance Equation for Non-Inertial Particles Dynamics Using Probability Density Function and Neural Networks},
  author = {Seltz, Andrea and Domingo, Pascale and Vervisch, Luc},
  year = {2021},
  month = jan,
  journal = {Physics of Fluids},
  volume = {33},
  number = {1},
  pages = {013311},
  issn = {1070-6631},
  doi = {10.1063/5.0031144},
  urldate = {2023-07-08},
  abstract = {Numerical modeling of non-inertial particles dynamics is usually addressed by solving a population balance equation (PBE). In addition to space and time, a discretization is required also in the particle-size space, covering a large range of variation controlled by strongly nonlinear phenomena. A novel approach is presented in which a hybrid stochastic/fixed-sectional method solving the PBE is used to train a combination of an artificial neural network (ANN) with a convolutional neural network (CNN) and recurrent long short-term memory artificial neural layers. The hybrid stochastic/fixed-sectional method decomposes the problem into the total number density and the probability density function of sizes, allowing for an accurate treatment of surface growth/loss. After solving for the transport of species and temperature, the input of the ANN is composed of the thermochemical parameters controlling the particle physics and of the increment in time. The input of the CNN is the shape of the particle size distribution (PSD) discretized in sections of size. From these inputs, in a flow simulation, the ANN\textendash CNN returns the PSD shape for the subsequent time step or a source term for the Eulerian transport of the particle size density. The method is evaluated in a canonical laminar premixed sooting flame of the literature, and for a given level of accuracy (i.e., a given discretization of the size space), a significant computing cost reduction is achieved (six times faster compared to a sectional method with ten sections and 30 times faster for 100 sections).},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Physics of Fluids/2021/Seltz et al_2021_Solving the population balance equation for non-inertial particles dynamics.pdf;/Users/steven/Zotero/storage/ALD7NR4F/Solving-the-population-balance-equation-for-non.html}
}

@article{singhChallengesOpportunitiesConcerning2022,
  title = {Challenges and Opportunities Concerning Numerical Solutions for Population Balances: A Critical Review},
  shorttitle = {Challenges and Opportunities Concerning Numerical Solutions for Population Balances},
  author = {Singh, Mehakpreet and Ranade, Vivek and Shardt, Orest and Matsoukas, Themis},
  year = {2022},
  month = sep,
  journal = {Journal of Physics A: Mathematical and Theoretical},
  volume = {55},
  number = {38},
  pages = {383002},
  publisher = {{IOP Publishing}},
  issn = {1751-8121},
  doi = {10.1088/1751-8121/ac8a42},
  urldate = {2023-07-08},
  abstract = {Population balance models are tools for the study of dispersed systems, such as granular materials, polymers, colloids and aerosols. They are applied with increasing frequency across a wide range of disciplines, including chemical engineering, aerosol physics, astrophysics, polymer science, pharmaceutical sciences, and mathematical biology. Population balance models are used to track particle properties and their changes due to aggregation, fragmentation, nucleation and growth, processes that directly affect the distribution of particle sizes. The population balance equation is an integro-partial differential equation whose domain is the line of positive real numbers. This poses challenges for the stability and accuracy of the numerical methods used to solve for size distribution function and in response to these challenges several different methodologies have been developed in the literature. This review provides a critical presentation of the state of the art in numerical approaches for solving these complex models with emphasis in the algorithmic details that distinguish each methodology. The review covers finite volume methods, Monte Carlo method and sectional methods; the method of moments, another important numerical methodology, is not covered in this review.},
  langid = {english},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of Physics A Mathematical and Theoretical/2022/Singh et al_2022_Challenges and opportunities concerning numerical solutions for population.pdf}
}

@article{sotolongo-costaNonextensiveStatisticalModel2015,
  title = {A Non-Extensive Statistical Model for Time-Dependent Multiple Breakage Particle-Size Distribution},
  author = {{Sotolongo-Costa}, O. and {Gaggero-Sager}, L. M. and {Mora-Ramos}, M. E.},
  year = {2015},
  month = nov,
  journal = {Physica A: Statistical Mechanics and its Applications},
  volume = {438},
  pages = {74--80},
  issn = {0378-4371},
  doi = {10.1016/j.physa.2015.06.042},
  urldate = {2023-07-08},
  abstract = {A general formulation for the statistical description of time-dependent multiple particle breakage processes is presented in terms of a purposely constructed dimensionless quantity that contains the main physical magnitudes involved in the problem. The approach combines the Tsallis non-extensive entropy with a kinetic equation with fractionary index for the time evolution of the size/mass of the fragments. The obtained distribution function is tested by fitting some experimental reports. It is found that the better adjustment corresponds, in all cases, to values of the time index equal or below 0.6, whereas the parameter of nonextensivity ranks between 1 and 2, as previously reported in other studies involving some kind of fragmentation. The work could be the first example of a non-extensive maximum-entropy statistical description based on a purposely constructed dimensionless quantity, as well as of the derivation of a fragment size distribution function explicitly dependent on measurable system variables. As a result, the role of quantities such as viscosity, velocity gradient and others becomes explicit in the formulation.},
  langid = {english},
  keywords = {Multiple particle breakage,Nonextensive statistics,Time dependence},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/undefined/2015/Sotolongo-Costa et al. - 2015 - A non-extensive statistical model for time-depende.pdf;/Users/steven/Zotero/storage/Q52YSXMH/S0378437115006020.html}
}

@article{tibshiraniEstimatingNumberClusters2001,
  title = {Estimating the Number of Clusters in a Data Set via the Gap Statistic},
  author = {Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
  year = {2001},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {63},
  number = {2},
  pages = {411--423},
  issn = {1467-9868},
  doi = {10.1111/1467-9868.00293},
  urldate = {2023-07-08},
  abstract = {We propose a method (the `gap statistic') for estimating the number of clusters (groups) in a set of data. The technique uses the output of any clustering algorithm (e.g. K-means or hierarchical), comparing the change in within-cluster dispersion with that expected under an appropriate reference null distribution. Some theory is developed for the proposal and a simulation study shows that the gap statistic usually outperforms other methods that have been proposed in the literature.},
  copyright = {2001 Royal Statistical Society},
  langid = {english},
  keywords = {Clustering,Groups,Hierarchy,Uniform distribution},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Journal of the Royal Statistical Society Series B (Statistical Methodology)/2001/Tibshirani et al_2001_Estimating the number of clusters in a data set via the gap statistic.pdf;/Users/steven/Zotero/storage/KU3F2Z9H/1467-9868.html}
}

@article{wangNewMethodSolving2020,
  title = {A New Method for Solving Population Balance Equations Using a Radial Basis Function Network},
  author = {Wang, Kaiyuan and Yu, Suyuan and Peng, Wei},
  year = {2020},
  month = jun,
  journal = {Aerosol Science and Technology},
  volume = {54},
  number = {6},
  pages = {644--655},
  publisher = {{Taylor \& Francis}},
  issn = {0278-6826},
  doi = {10.1080/02786826.2019.1711358},
  urldate = {2023-07-08},
  abstract = {This study presents a new method for solving the population balance equation (PBE) for particle coagulation. The method introduces a radial basis function network to approximate the number density function. The approximate solution should satisfy the PBE at the collocation points in a continuous manner. The coagulation terms in the PBE are directly handled using the Gaussian quadrature techniques. The final solution is a bivariant analytical function of particle volume and time, which can be easily used in any subsequent calculation. Then the method is validated by comparing with analytical solutions and the sectional method for four numerical test problems. These problems are selected to vary in coagulation kernels and initial conditions. The comparative results show that the present method can accurately predict the time evolution of the number density function. Moreover, the computational efficiency of the present method is quite acceptable considering the high accuracy.Copyright \textcopyright{} 2020 American Association for Aerosol Research},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/Aerosol Science and Technology/2020/Wang et al_2020_A new method for solving population balance equations using a radial basis.pdf}
}

@article{zhangStatisticalInferencesFunctional2007,
  title = {Statistical Inferences for Functional Data},
  author = {Zhang, Jin-Ting and Chen, Jianwei},
  year = {2007},
  month = jul,
  journal = {The Annals of Statistics},
  volume = {35},
  number = {3},
  pages = {1052--1079},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0090-5364, 2168-8966},
  doi = {10.1214/009053606000001505},
  urldate = {2023-07-08},
  abstract = {With modern technology development, functional data are being observed frequently in many scientific fields. A popular method for analyzing such functional data is ``smoothing first, then estimation.'' That is, statistical inference such as estimation and hypothesis testing about functional data is conducted based on the substitution of the underlying individual functions by their reconstructions obtained by one smoothing technique or another. However, little is known about this substitution effect on functional data analysis. In this paper this problem is investigated when the local polynomial kernel (LPK) smoothing technique is used for individual function reconstructions. We find that under some mild conditions, the substitution effect can be ignored asymptotically. Based on this, we construct LPK reconstruction-based estimators for the mean, covariance and noise variance functions of a functional data set and derive their asymptotics. We also propose a GCV rule for selecting good bandwidths for the LPK reconstructions. When the mean function also depends on some time-independent covariates, we consider a functional linear model where the mean function is linearly related to the covariates but the covariate effects are functions of time. The LPK reconstruction-based estimators for the covariate effects and the covariance function are also constructed and their asymptotics are derived. Moreover, we propose a L2-norm-based global test statistic for a general hypothesis testing problem about the covariate effects and derive its asymptotic random expression. The effect of the bandwidths selected by the proposed GCV rule on the accuracy of the LPK reconstructions and the mean function estimator is investigated via a simulation study. The proposed methodologies are illustrated via an application to a real functional data set collected in climatology.},
  keywords = {62G07,62G10,62J12,Asymptotic Gaussian process,Asymptotic normal distribution,functional data,hypothesis test,local polynomial smoothing,nonparametric estimation,reconstructed individual functions,root-n consistent},
  file = {/Users/steven/Library/CloudStorage/GoogleDrive-steven.golovkine@ul.ie/My Drive/bibliography/The Annals of Statistics/2007/Zhang_Chen_2007_Statistical inferences for functional data.pdf}
}
